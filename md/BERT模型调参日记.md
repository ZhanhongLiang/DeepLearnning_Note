# é¡¹ç›®å·¥ç¨‹ç»“æ„

## å·¥ç¨‹ç»“æ„

- `bert_base_chinese`ç›®å½•ä¸­æ˜¯BERT baseä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹ä»¥åŠé…ç½®æ–‡ä»¶

  æ¨¡å‹ä¸‹è½½åœ°å€ï¼š<https://huggingface.co/bert-base-chinese/tree/main>

- `bert_base_uncased_english`ç›®å½•ä¸­æ˜¯BERT baseè‹±æ–‡é¢„è®­ç»ƒæ¨¡å‹ä»¥åŠé…ç½®æ–‡ä»¶

  æ¨¡å‹ä¸‹è½½åœ°å€ï¼š<https://huggingface.co/bert-base-uncased/tree/main>

  æ³¨æ„ï¼š`config.json`ä¸­éœ€è¦æ·»åŠ `"pooler_type": "first_token_transform"`è¿™ä¸ªå‚æ•°

- `data`ç›®å½•ä¸­æ˜¯å„ä¸ªä¸‹æ¸¸ä»»åŠ¡æ‰€ä½¿ç”¨åˆ°çš„æ•°æ®é›†

  - `SingleSentenceClassification`æ˜¯ä»Šæ—¥å¤´æ¡çš„15åˆ†ç±»ä¸­æ–‡æ•°æ®é›†ï¼›
  - `PairSentenceClassification`æ˜¯MNLIï¼ˆThe Multi-Genre Natural Language Inference Corpus, å¤šç±»å‹è‡ªç„¶è¯­è¨€æ¨ç†æ•°æ®åº“ï¼‰æ•°æ®é›†ï¼›
  - `MultipeChoice`æ˜¯SWAGé—®é¢˜é€‰æ‹©æ•°æ®é›†
  - `SQuAD`æ˜¯æ–¯å¦ç¦å¤§å­¦å¼€æºçš„é—®ç­”æ•°æ®é›†1.1ç‰ˆæœ¬
  - `WikiText`æ˜¯ç»´åŸºç™¾ç§‘è‹±æ–‡è¯­æ–™ç”¨äºæ¨¡å‹é¢„è®­ç»ƒ
  - `SongCi`æ˜¯å®‹è¯è¯­æ–™ç”¨äºä¸­æ–‡æ¨¡å‹é¢„è®­ç»ƒ
  - `ChineseNER`æ˜¯ç”¨äºè®­ç»ƒä¸­æ–‡å‘½åä½“è¯†åˆ«çš„æ•°æ®é›†

- `model`ç›®å½•ä¸­æ˜¯å„ä¸ªæ¨¡å—çš„å®ç°

  - ```
    BasicBertä¸­æ˜¯åŸºç¡€çš„BERTæ¨¡å‹å®ç°æ¨¡å—
    ```

    - `MyTransformer.py`æ˜¯è‡ªæ³¨æ„åŠ›æœºåˆ¶å®ç°éƒ¨åˆ†ï¼›
    - `BertEmbedding.py`æ˜¯Input Embeddingå®ç°éƒ¨åˆ†ï¼›
    - `BertConfig.py`ç”¨äºå¯¼å…¥å¼€æºçš„`config.json`é…ç½®æ–‡ä»¶ï¼›
    - `Bert.py`æ˜¯BERTæ¨¡å‹çš„å®ç°éƒ¨åˆ†ï¼›

  - ```
    DownstreamTasksç›®å½•æ˜¯ä¸‹æ¸¸ä»»åŠ¡å„ä¸ªæ¨¡å—çš„å®ç°
    ```

    - `BertForSentenceClassification.py`æ˜¯å•æ ‡ç­¾å¥å­åˆ†ç±»çš„å®ç°éƒ¨åˆ†ï¼›
    - `BertForMultipleChoice.py`æ˜¯é—®é¢˜é€‰æ‹©æ¨¡å‹çš„å®ç°éƒ¨åˆ†ï¼›
    - `BertForQuestionAnswering.py`æ˜¯é—®é¢˜å›ç­”ï¼ˆtext spanï¼‰æ¨¡å‹çš„å®ç°éƒ¨åˆ†ï¼›
    - `BertForNSPAndMLM.py`æ˜¯BERTæ¨¡å‹é¢„è®­ç»ƒçš„ä¸¤ä¸ªä»»åŠ¡å®ç°éƒ¨åˆ†ï¼›
    - `BertForTokenClassification.py`æ˜¯å­—ç¬¦åˆ†ç±»ï¼ˆå¦‚ï¼šå‘½åä½“è¯†åˆ«ï¼‰æ¨¡å‹çš„å®ç°éƒ¨åˆ†ï¼›

- `Task`ç›®å½•ä¸­æ˜¯å„ä¸ªå…·ä½“ä¸‹æ¸¸ä»»åŠ¡çš„è®­ç»ƒå’Œæ¨ç†å®ç°

  - `TaskForSingleSentenceClassification.py`æ˜¯å•æ ‡ç­¾å•æ–‡æœ¬åˆ†ç±»ä»»åŠ¡çš„è®­ç»ƒå’Œæ¨ç†å®ç°ï¼Œå¯ç”¨äºæ™®é€šçš„æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼›
  - `TaskForPairSentence.py`æ˜¯æ–‡æœ¬å¯¹åˆ†ç±»ä»»åŠ¡çš„è®­ç»ƒå’Œæ¨ç†å®ç°ï¼Œå¯ç”¨äºè•´å«ä»»åŠ¡ï¼ˆä¾‹å¦‚MNLIæ•°æ®é›†ï¼‰ï¼›
  - `TaskForMultipleChoice.py`æ˜¯é—®ç­”é€‰æ‹©ä»»åŠ¡çš„è®­ç»ƒå’Œæ¨ç†å®ç°ï¼Œå¯ç”¨äºé—®ç­”é€‰æ‹©ä»»åŠ¡ï¼ˆä¾‹å¦‚SWAGæ•°æ®é›†ï¼‰ï¼›
  - `TaskForSQuADQuestionAnswering.py`æ˜¯é—®é¢˜å›ç­”ä»»åŠ¡çš„è®­ç»ƒå’Œæ¨ç†å®ç°ï¼Œå¯ç”¨äºé—®é¢˜é—®ç­”ä»»åŠ¡ï¼ˆä¾‹å¦‚SQuADæ•°æ®é›†ï¼‰ï¼›
  - `TaskForPretraining.py`æ˜¯BERTæ¨¡å‹ä¸­MLMå’ŒNSPä¸¤ä¸ªé¢„è®­ç»ƒä»»åŠ¡çš„å®ç°éƒ¨åˆ†ï¼Œå¯ç”¨äºBERTæ¨¡å‹é¢„è®­ç»ƒï¼›
  - `TaskForChineseNER.py`æ˜¯åŸºäºBERTæ¨¡å‹çš„å‘½åä½“ä»»åŠ¡è®­ç»ƒå’Œæ¨ç†éƒ¨åˆ†çš„å®ç°ï¼›

- `test`ç›®å½•ä¸­æ˜¯å„ä¸ªæ¨¡å—çš„æµ‹è¯•æ¡ˆä¾‹

- `utils`æ˜¯å„ä¸ªå·¥å…·ç±»çš„å®ç°

  - `data_helpers.py`æ˜¯å„ä¸ªä¸‹æ¸¸ä»»åŠ¡çš„æ•°æ®é¢„å¤„ç†åŠæ•°æ®é›†æ„å»ºæ¨¡å—ï¼›
  - `log_helper.py`æ˜¯æ—¥å¿—æ‰“å°æ¨¡å—ï¼›
  - `creat_pretraining_data.py`æ˜¯ç”¨äºæ„é€ BERTé¢„è®­ç»ƒä»»åŠ¡çš„æ•°æ®é›†ï¼›



# ä¸‹æ¸¸ä»»åŠ¡ä¸€:  æ–‡æœ¬åˆ†ç±»ä»»åŠ¡

>`BERT`æ˜¯ä¸€ä¸ªå¼ºå¤§çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¯ä»¥åŸºäºè°·æ­Œå‘å¸ƒçš„é¢„è®­ç»ƒå‚æ•°åœ¨å„ä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸­è¿›è¡Œå¾®è°ƒ
>
>`åŸºäº BERTçš„æ–‡æœ¬åˆ†ç±»ï¼ˆå‡†ç¡®çš„æ˜¯å•æ–‡æœ¬ï¼Œä¹Ÿå°±æ˜¯è¾“å…¥åªåŒ…å«ä¸€ä¸ªå¥å­ï¼‰æ¨¡å‹å°±æ˜¯åœ¨åŸå§‹çš„ BERT æ¨¡å‹åå†åŠ ä¸Šä¸€ä¸ªåˆ†ç±»å±‚å³å¯`
>
>åˆ†ç±»å±‚å°±æ˜¯ç±»ä¼¼ä¸‹é¢å›¾ç‰‡ä¸­ä¸€æ ·ï¼Œåœ¨åŸæ¥æ¨¡å‹ä¸­æ·»åŠ åˆ†ç±»å±‚

![](https://pic.superbed.cc/item/66f13b2c991d0115df1252bc.png)

## ä»»åŠ¡æ„é€ åŸç†

>â€‹     æ€»çš„æ¥è¯´ï¼ŒåŸºäº BERTçš„æ–‡æœ¬åˆ†ç±»ï¼ˆå‡†ç¡®çš„æ˜¯å•æ–‡æœ¬ï¼Œä¹Ÿå°±æ˜¯è¾“å…¥åªåŒ…å«ä¸€ä¸ªå¥å­ï¼‰`æ¨¡å‹å°±æ˜¯åœ¨åŸå§‹çš„ BERT æ¨¡å‹åå†åŠ ä¸Šä¸€ä¸ªåˆ†ç±»å±‚å³å¯ï¼Œç±»ä¼¼çš„ç»“æ„æŒæŸœåœ¨æ–‡ç« [6]ï¼ˆåŸºäº Transformer çš„åˆ†ç±»æ¨¡å‹ï¼‰ä¸­ä¹Ÿä»‹ç»è¿‡ï¼Œå¤§å®¶å¯ä»¥å»çœ‹ä¸€ä¸‹ã€‚åŒæ—¶ï¼Œå¯¹äºåˆ†ç±»å±‚çš„è¾“å…¥ï¼ˆä¹Ÿå°±æ˜¯åŸå§‹ BERT çš„è¾“å‡ºï¼‰ï¼Œé»˜è®¤æƒ…å†µä¸‹å– BERTè¾“å‡ºç»“æœä¸­[CLS]ä½ç½®å¯¹äºçš„å‘é‡å³å¯ï¼Œå½“ç„¶ä¹Ÿå¯ä»¥ä¿®æ”¹ä¸ºå…¶å®ƒæ–¹å¼ï¼Œä¾‹å¦‚æ‰€æœ‰ä½ç½®å‘é‡çš„å‡å€¼ç­‰ï¼ˆè§ 2.4.3 èŠ‚å†…å®¹ï¼Œå°†é…ç½®æ–‡ä»¶ config.json ä¸­çš„ pooler_type å­—æ®µè®¾ç½®ä¸º"all_token_average"å³å¯`ã€‚
>
>â€‹    å› æ­¤ï¼Œå¯¹äºåŸºäº BERT çš„æ–‡æœ¬åˆ†ç±»æ¨¡å‹æ¥è¯´å…¶è¾“å…¥å°±æ˜¯ BERT çš„è¾“å…¥ï¼Œè¾“å‡ºåˆ™æ˜¯æ¯ä¸ªç±»åˆ«å¯¹åº”çš„ logits å€¼ã€‚æ¥ä¸‹æ¥ï¼ŒæŒæŸœé¦–å…ˆå°±æ¥ä»‹ç»å¦‚ä½•æ„é€ æ–‡æœ¬åˆ†ç±»çš„æ•°æ®é›†ã€‚

## æ•°æ®é¢„å¤„ç†

### è¾“å…¥æ•°æ®

>`å¯¹äºæ–‡æœ¬åˆ†ç±»é—®é¢˜è¾“å…¥åªæœ‰ä¸€ä¸ªåºåˆ—,æ„å»ºæ•°æ®é›†çš„æ—¶å€™ä¸éœ€è¦æ„é€ SegmentEmbeddingï¼Œç›´æ¥é»˜è®¤å…¨ä¸º0`
>
>`å¯¹äºæ–‡æœ¬åˆ†ç±»è¿™ä¸ªåœºæ™¯æ¥è¯´,åªéœ€è¦æ„é€ åŸå§‹æ–‡æœ¬å¯¹åº”çš„Tokenåºåˆ—ï¼Œé¦–å°¾åˆ†åˆ«å†åŠ ä¸Šä¸€ä¸ª[CLS]å’Œ[SEP]ç¬¦ä½œä¸ºè¾“å…¥å°±è¡Œ`

### æ•°æ®é›†åˆ†æ

![](https://pic.superbed.cc/item/66f140c3991d0115df13cab1.png)

>`â‘ å…ˆè¿›è¡Œ Tokenizeå¤„ç† ->  â‘¡ä½¿ç”¨è°·æ­Œå¼€æºçš„vocab.txtæ–‡ä»¶æ„é€ å­—å…¸ï¼Œä¸éœ€è¦è‡ªå·±æ„é€ å­—å…¸ -> â‘¢æ ¹æ®å­—å…¸å°†tokenizeåçš„æ–‡æœ¬åºåˆ—è½¬æ¢ä¸ºTokenåºåˆ—,åŒæ—¶å†Tokenåºåˆ—çš„é¦–å°¾åŠ ä¸Š[CLS]å’Œ[SEP]ç¬¦å·,å¹¶è¿›è¡ŒPadding->â‘£å°±æ˜¯æ ¹æ®ç¬¬3æ­¥å¤„ç†åçš„ç»“æœç”Ÿæˆå¯¹åº”çš„Padding Maskå‘é‡`

## æ•°æ®é›†æ„å»º

### â‘ å®šä¹‰tokenize

>å’Œtransformersæ¨¡å‹ç±»ä¼¼ï¼Œéœ€è¦å…ˆå¯¹æ–‡æœ¬è¿›è¡Œtokenizeræ“ä½œ

```python
# Tokenizerçš„æ“ä½œ,åº•å±‚æºç ä¸ç”¨ç®¡
import sys
sys.path.append('../')
from Tasks.TaskForSingleSentenceClassification import ModelConfig
from transformers import BertTokenizer

if __name__ == '__main__':
    model_config = ModelConfig()
    tokenizer = BertTokenizer.from_pretrained(model_config.pretrained_model_dir).tokenize
    print(tokenizer("é’å±±ä¸æ”¹ï¼Œç»¿æ°´é•¿æµï¼Œæˆ‘ä»¬æœˆæ¥å®¢æ ˆè§ï¼"))
    print(tokenizer("10 å¹´å‰çš„ä»Šå¤©ï¼Œçºªå¿µ 5.12 æ±¶å·å¤§åœ°éœ‡ 10 å‘¨å¹´"))
```

```
['é’', 'å±±', 'ä¸', 'æ”¹', 'ï¼Œ', 'ç»¿', 'æ°´', 'é•¿', 'æµ', 'ï¼Œ', 'æˆ‘', 'ä»¬', 'æœˆ', 'æ¥', 'å®¢', 'æ ˆ', 'è§', 'ï¼']
['10', 'å¹´', 'å‰', 'çš„', 'ä»Š', 'å¤©', 'ï¼Œ', 'çºª', 'å¿µ', '5', '.', '12', 'æ±¶', 'å·', 'å¤§', 'åœ°', 'éœ‡', '10', 'å‘¨', 'å¹´']
```

### â‘¡ å»ºç«‹è¯è¡¨

>å› ä¸ºè°·æ­Œæ˜¯å¼€æºäº† vocab.txt è¯è¡¨,  ä¸éœ€è¦æ ¹æ®è‡ªå·±çš„è¯­æ–™æ¥å»ºç«‹ä¸€ä¸ªè¯è¡¨
>
>`ä¸èƒ½æ ¹æ®è‡ªå·±çš„è¯­æ–™æ¥æ„å»ºè¯è¡¨`,å› ä¸ºå½“ç”¨è‡ªå·±çš„è¯­æ–™æ„å»ºè¯è¡¨çš„æ—¶å€™ï¼Œä¼šå¯¼è‡´åæœŸæå–çš„token.idæ˜¯é”™è¯¯çš„

>è¯¥æ–‡ä»¶åœ¨"/media/wislab/Dataset_SSD2T/lzh/BertWithPretrained/utils/data_helpers.py"

```python
class Vocab:
    """
    æ ¹æ®æœ¬åœ°çš„vocabæ–‡ä»¶ï¼Œæ„é€ ä¸€ä¸ªè¯è¡¨
    vocab = Vocab()
    print(vocab.itos)  # å¾—åˆ°ä¸€ä¸ªåˆ—è¡¨ï¼Œè¿”å›è¯è¡¨ä¸­çš„æ¯ä¸€ä¸ªè¯ï¼›
    print(vocab.itos[2])  # é€šè¿‡ç´¢å¼•è¿”å›å¾—åˆ°è¯è¡¨ä¸­å¯¹åº”çš„è¯ï¼›
    print(vocab.stoi)  # å¾—åˆ°ä¸€ä¸ªå­—å…¸ï¼Œè¿”å›è¯è¡¨ä¸­æ¯ä¸ªè¯çš„ç´¢å¼•ï¼›
    print(vocab.stoi['æˆ‘'])  # é€šè¿‡å•è¯è¿”å›å¾—åˆ°è¯è¡¨ä¸­å¯¹åº”çš„ç´¢å¼•
    print(len(vocab))  # è¿”å›è¯è¡¨é•¿åº¦
    """
    UNK = '[UNK]'

    def __init__(self, vocab_path):
        # å­—å…¸key:values,è¿”å›è¯è¡¨ä¸­æ¯ä¸ªè¯çš„ç´¢å¼•
        self.stoi = {}
        # æ•°ç»„ä»£è¡¨åˆ—è¡¨,è¿”å›è¯è¡¨ä¸­æ¯ä¸€ä¸ªè¯
        self.itos = []
        # æ‰“å¼€vocab_pathè·¯å¾„,ç”¨\nè¿›è¡Œåˆ†å‰²,ç„¶å
        with open(vocab_path, 'r', encoding='utf-8') as f:
            for i, word in enumerate(f):
                w = word.strip('\n')
                self.stoi[w] = i
                self.itos.append(w)

    def __getitem__(self, token):
        return self.stoi.get(token, self.stoi.get(Vocab.UNK))

    def __len__(self):
        return len(self.itos)


def build_vocab(vocab_path):
    """
    vocab = Vocab()
    print(vocab.itos)  # å¾—åˆ°ä¸€ä¸ªåˆ—è¡¨ï¼Œè¿”å›è¯è¡¨ä¸­çš„æ¯ä¸€ä¸ªè¯ï¼›
    print(vocab.itos[2])  # é€šè¿‡ç´¢å¼•è¿”å›å¾—åˆ°è¯è¡¨ä¸­å¯¹åº”çš„è¯ï¼›
    print(vocab.stoi)  # å¾—åˆ°ä¸€ä¸ªå­—å…¸ï¼Œè¿”å›è¯è¡¨ä¸­æ¯ä¸ªè¯çš„ç´¢å¼•ï¼›
    print(vocab.stoi['æˆ‘'])  # é€šè¿‡å•è¯è¿”å›å¾—åˆ°è¯è¡¨ä¸­å¯¹åº”çš„ç´¢å¼•
    """
    return Vocab(vocab_path)
```

>åœ¨ç»è¿‡ä¸Šè¿°ä»£ç å¤„ç†åï¼Œæˆ‘ä»¬ä¾¿èƒ½å¤Ÿé€šè¿‡ vocab.itos å¾—åˆ°ä¸€ä¸ªåˆ—è¡¨ï¼Œè¿”å›è¯è¡¨ä¸­çš„æ¯ä¸€ä¸ªè¯ï¼›é€šè¿‡ vocab.itos[2]è¿”å›å¾—åˆ°è¯è¡¨ä¸­å¯¹åº”ç´¢å¼•ä½ç½®ä¸Šçš„è¯ï¼›é€šè¿‡vocab.stoi å¾—åˆ°ä¸€ä¸ªå­—å…¸ï¼Œè¿”å›è¯è¡¨ä¸­æ¯ä¸ªè¯çš„ç´¢å¼•ï¼›é€šè¿‡ vocab.stoi['æœˆ']è¿”å›å¾—åˆ°è¯è¡¨ä¸­å¯¹åº”è¯çš„ç´¢å¼•ï¼›é€šè¿‡ len(vocab)æ¥è¿”å›è¯è¡¨çš„é•¿åº¦ã€‚å¦‚ä¸‹ä¾¿æ˜¯å»ºç«‹åçš„è¯è¡¨

```
': 21027, '##é½’': 21028, '##é½¡': 21029, '##é½¢': 21030, '##é½£': 21031, '##é½¦': 21032, '##é½¿': 21033, '##é¾„': 21034, '##é¾…': 21035, '##é¾ˆ': 21036, '##é¾Š': 21037, '##é¾‹': 21038, '##é¾Œ': 21039, '##é¾': 21040, '##é¾': 21041, '##é¾”': 21042, '##é¾•': 21043, '##é¾™': 21044, '##é¾š': 21045, '##é¾›': 21046, '##é¾œ': 21047, '##é¾Ÿ': 21048, '##ï¸°': 21049, '##ï¸±': 21050, '##ï¸¶': 21051, '##ï¸¿': 21052, '##ï¹': 21053, '##ï¹‚': 21054, '##ï¹': 21055, '##ï¹': 21056, '##ï¹': 21057, '##ï¹‘': 21058, '##ï¹’': 21059, '##ï¹”': 21060, '##ï¹•': 21061, '##ï¹–': 21062, '##ï¹—': 21063, '##ï¹™': 21064, '##ï¹š': 21065, '##ï¹': 21066, '##ï¹': 21067, '##ï¹¡': 21068, '##ï¹£': 21069, '##ï¼': 21070, '##ï¼‚': 21071, '##ï¼ƒ': 21072, '##ï¼„': 21073, '##ï¼…': 21074, '##ï¼†': 21075, '##ï¼‡': 21076, '##ï¼ˆ': 21077, '##ï¼‰': 21078, '##ï¼Š': 21079, '##ï¼Œ': 21080, '##ï¼': 21081, '##ï¼': 21082, '##ï¼': 21083, '##ï¼š': 21084, '##ï¼›': 21085, '##ï¼œ': 21086, '##ï¼Ÿ': 21087, '##ï¼ ': 21088, '##ï¼»': 21089, '##ï¼¼': 21090, '##ï¼½': 21091, '##ï¼¾': 21092, '##ï¼¿': 21093, '##ï½€': 21094, '##ï½†': 21095, '##ï½ˆ': 21096, '##ï½Š': 21097, '##ï½•': 21098, '##ï½—': 21099, '##ï½š': 21100, '##ï½›': 21101, '##ï½': 21102, '##ï½¡': 21103, '##ï½¢': 21104, '##ï½£': 21105, '##ï½¤': 21106, '##ï½¥': 21107, '##ï½¯': 21108, '##ï½°': 21109, '##ï½²': 21110, '##ï½¸': 21111, '##ï½¼': 21112, '##ï½½': 21113, '##ï¾„': 21114, '##ï¾‰': 21115, '##ï¾Œ': 21116, '##ï¾—': 21117, '##ï¾™': 21118, '##ï¾': 21119, '##ï¾': 21120, '##ï¾Ÿ': 21121, '##ï¿£': 21122, '##ï¿¥': 21123, '##ğŸ‘': 21124, '##ğŸ”¥': 21125, '##ğŸ˜‚': 21126, '##ğŸ˜': 21127}
2769
```



- é›†æˆç±»ä¸­è¿›è¡ŒåŠ è½½

```python
class LoadSingleSentenceClassificationDataset:
    def __init__(self,
                 vocab_path='./vocab.txt',  #
                 tokenizer=None,
                 batch_size=32,
                 max_sen_len=None,
                 split_sep='\n',
                 max_position_embeddings=512,
                 pad_index=0,
                 is_sample_shuffle=True
                 ):

        """

        :param vocab_path: æœ¬åœ°è¯è¡¨vocab.txtçš„è·¯å¾„
        :param tokenizer:
        :param batch_size:
        :param max_sen_len: åœ¨å¯¹æ¯ä¸ªbatchè¿›è¡Œå¤„ç†æ—¶çš„é…ç½®ï¼›
                            å½“max_sen_len = Noneæ—¶ï¼Œå³ä»¥æ¯ä¸ªbatchä¸­æœ€é•¿æ ·æœ¬é•¿åº¦ä¸ºæ ‡å‡†ï¼Œå¯¹å…¶å®ƒè¿›è¡Œpadding
                            å½“max_sen_len = 'same'æ—¶ï¼Œä»¥æ•´ä¸ªæ•°æ®é›†ä¸­æœ€é•¿æ ·æœ¬ä¸ºæ ‡å‡†ï¼Œå¯¹å…¶å®ƒè¿›è¡Œpadding
                            å½“max_sen_len = 50ï¼Œ è¡¨ç¤ºä»¥æŸä¸ªå›ºå®šé•¿åº¦ç¬¦æ ·æœ¬è¿›è¡Œpaddingï¼Œå¤šä½™çš„æˆªæ‰ï¼›
        :param split_sep: æ–‡æœ¬å’Œæ ‡ç­¾ä¹‹å‰çš„åˆ†éš”ç¬¦ï¼Œé»˜è®¤ä¸º'\t'
        :param max_position_embeddings: æŒ‡å®šæœ€å¤§æ ·æœ¬é•¿åº¦ï¼Œè¶…è¿‡è¿™ä¸ªé•¿åº¦çš„éƒ¨åˆ†å°†æœ¬æˆªå–æ‰
        :param is_sample_shuffle: æ˜¯å¦æ‰“ä¹±è®­ç»ƒé›†æ ·æœ¬ï¼ˆåªé’ˆå¯¹è®­ç»ƒé›†ï¼‰
                åœ¨åç»­æ„é€ DataLoaderæ—¶ï¼ŒéªŒè¯é›†å’Œæµ‹è¯•é›†å‡æŒ‡å®šä¸ºäº†å›ºå®šé¡ºåºï¼ˆå³ä¸è¿›è¡Œæ‰“ä¹±ï¼‰ï¼Œä¿®æ”¹ç¨‹åºæ—¶è¯·å‹¿è¿›è¡Œæ‰“ä¹±
                å› ä¸ºå½“shuffleä¸ºTrueæ—¶ï¼Œæ¯æ¬¡é€šè¿‡forå¾ªç¯éå†data_iteræ—¶æ ·æœ¬çš„é¡ºåºéƒ½ä¸ä¸€æ ·ï¼Œè¿™ä¼šå¯¼è‡´åœ¨æ¨¡å‹é¢„æµ‹æ—¶
                è¿”å›çš„æ ‡ç­¾é¡ºåºä¸åŸå§‹çš„é¡ºåºä¸ä¸€æ ·ï¼Œä¸æ–¹ä¾¿å¤„ç†ã€‚

        """
        self.tokenizer = tokenizer
        # æ„å»ºè¯è¡¨ï¼Œè¿”å›Vocabå¯¹è±¡
        self.vocab = build_vocab(vocab_path)
        self.PAD_IDX = pad_index
        # SEP_IDXæ˜¯ä¸¤ä¸ªå¥å­åˆ†å¼€çš„æ ‡å¿—
        self.SEP_IDX = self.vocab['[SEP]']
        # CLSæ˜¯å¥å­ä¹‹é—´å¼€å¤´ä½ç½®
        self.CLS_IDX = self.vocab['[CLS]']
        # self.UNK_IDX = '[UNK]'

        self.batch_size = batch_size
        self.split_sep = split_sep
        self.max_position_embeddings = max_position_embeddings
        if isinstance(max_sen_len, int) and max_sen_len > max_position_embeddings:
            max_sen_len = max_position_embeddings
        self.max_sen_len = max_sen_len
        self.is_sample_shuffle = is_sample_shuffle

    @process_cache(unique_key=["max_sen_len"])
    def data_process(self, file_path=None):
        """
        å°†æ¯ä¸€å¥è¯ä¸­çš„æ¯ä¸€ä¸ªè¯æ ¹æ®å­—å…¸è½¬æ¢æˆç´¢å¼•çš„å½¢å¼ï¼ŒåŒæ—¶è¿”å›æ‰€æœ‰æ ·æœ¬ä¸­æœ€é•¿æ ·æœ¬çš„é•¿åº¦
        :param file_path: æ•°æ®é›†è·¯å¾„
        :return:
        """
        raw_iter = open(file_path, encoding="utf8").readlines()
        data = []
        max_len = 0
        for raw in tqdm(raw_iter, ncols=80):
            line = raw.rstrip("\n").split(self.split_sep)
            s, l = line[0], line[1]
            tmp = [self.CLS_IDX] + [self.vocab[token] for token in self.tokenizer(s)]
            if len(tmp) > self.max_position_embeddings - 1:
                tmp = tmp[:self.max_position_embeddings - 1]  # BERTé¢„è®­ç»ƒæ¨¡å‹åªå–å‰512ä¸ªå­—ç¬¦
            tmp += [self.SEP_IDX]
            tensor_ = torch.tensor(tmp, dtype=torch.long)
            l = torch.tensor(int(l), dtype=torch.long)
            max_len = max(max_len, tensor_.size(0))
            data.append((tensor_, l))
        return data, max_len

    def load_train_val_test_data(self, train_file_path=None,
                                 val_file_path=None,
                                 test_file_path=None,
                                 only_test=False):
        test_data, _ = self.data_process(file_path=test_file_path)
        test_iter = DataLoader(test_data, batch_size=self.batch_size,
                               shuffle=False, collate_fn=self.generate_batch)
        if only_test:
            return test_iter
        train_data, max_sen_len = self.data_process(file_path=train_file_path)  # å¾—åˆ°å¤„ç†å¥½çš„æ‰€æœ‰æ ·æœ¬
        if self.max_sen_len == 'same':
            self.max_sen_len = max_sen_len
        val_data, _ = self.data_process(file_path=val_file_path)
        train_iter = DataLoader(train_data, batch_size=self.batch_size,  # æ„é€ DataLoader
                                shuffle=self.is_sample_shuffle, collate_fn=self.generate_batch)
        val_iter = DataLoader(val_data, batch_size=self.batch_size,
                              shuffle=False, collate_fn=self.generate_batch)
        return train_iter, test_iter, val_iter

    def generate_batch(self, data_batch):
        batch_sentence, batch_label = [], []
        for (sen, label) in data_batch:  # å¼€å§‹å¯¹ä¸€ä¸ªbatchä¸­çš„æ¯ä¸€ä¸ªæ ·æœ¬è¿›è¡Œå¤„ç†ã€‚
            batch_sentence.append(sen)
            batch_label.append(label)
        batch_sentence = pad_sequence(batch_sentence,  # [batch_size,max_len]
                                      padding_value=self.PAD_IDX,
                                      batch_first=False,
                                      max_len=self.max_sen_len)
        batch_label = torch.tensor(batch_label, dtype=torch.long)
        return batch_sentence, batch_label
```

>å¹¶åœ¨ç±»çš„åˆå§‹åŒ–è¿‡ç¨‹ä¸­æ ¹æ®è®­ç»ƒè¯­æ–™å®Œæˆå­—å…¸çš„æ„å»ºç­‰å·¥ä½œ
>
>`è¯¥æ–‡ä»¶ä¹Ÿåœ¨:"/media/wislab/Dataset_SSD2T/lzh/BertWithPretrained/utils/data_helpers.py"`
>
>å½“ max_sen_len = None æ—¶ï¼Œå³ä»¥æ¯ä¸ª batch ä¸­æœ€é•¿æ ·æœ¬é•¿åº¦ä¸ºæ ‡å‡†ï¼Œå¯¹å…¶å®ƒè¿›è¡Œ paddingï¼›å½“ max_sen_len = 'same'æ—¶ï¼Œä»¥æ•´ä¸ªæ•°æ®é›†ä¸­æœ€é•¿æ ·æœ¬ä¸ºæ ‡å‡†ï¼Œå¯¹å…¶å®ƒè¿›è¡Œ paddingï¼›å½“ max_sen_len = 50ï¼Œ è¡¨ç¤ºä»¥æŸä¸ªå›ºå®šé•¿åº¦ç¬¦æ ·æœ¬è¿›è¡Œ paddingï¼Œå¤šä½™çš„æˆªæ‰
>
>split_sepè¡¨ç¤ºæ ·æœ¬ä¸æ ‡ç­¾ä¹‹é—´çš„åˆ†éš”ç¬¦ã€‚is_sample_shuffle è¡¨ç¤ºæ˜¯å¦æ‰“ä¹±æ•°æ®é›†

### â‘¢ è½¬æ¢ä¸ºTokenåºåˆ—

- åˆ©ç”¨tqdmè¿›è¡Œæ˜¾ç¤ºè®­ç»ƒçš„è¿›åº¦

```python
    """
    tqdmåº“ï¼Œç”¨äºæ˜¾ç¤ºpythonåº“è®­ç»ƒçš„è¿›åº¦
    åªæ˜¯ä¸€ä¸ªä¸‰æ–¹åº“
    """
    @process_cache(unique_key=["max_sen_len"])
    def data_process(self, file_path=None):
        """
        å°†æ¯ä¸€å¥è¯ä¸­çš„æ¯ä¸€ä¸ªè¯æ ¹æ®å­—å…¸è½¬æ¢æˆç´¢å¼•çš„å½¢å¼ï¼ŒåŒæ—¶è¿”å›æ‰€æœ‰æ ·æœ¬ä¸­æœ€é•¿æ ·æœ¬çš„é•¿åº¦
        :param file_path: æ•°æ®é›†è·¯å¾„
        :return:
        """
        # openå‡½æ•°
        # ä¸”è°ƒç”¨readlines()å‡½æ•°
        # è°ƒç”¨readline()å¯ä»¥æ¯æ¬¡è¯»å–ä¸€è¡Œå†…å®¹ï¼Œè°ƒç”¨readlines()ä¸€æ¬¡è¯»å–æ‰€æœ‰å†…å®¹å¹¶æŒ‰è¡Œè¿”å›listã€‚å› æ­¤ï¼Œè¦æ ¹æ®éœ€è¦å†³å®šæ€ä¹ˆè°ƒç”¨ã€‚
        raw_iter = open(file_path, encoding="utf8").readlines()
        data = []
        max_len = 0
        # tqdmåº“ï¼Œå°±æ˜¯æŒ‰ç…§
        for raw in tqdm(raw_iter, ncols=80):
            line = raw.rstrip("\n").split(self.split_sep)
            s, l = line[0], line[1]
            tmp = [self.CLS_IDX] + [self.vocab[token] for token in self.tokenizer(s)]
            if len(tmp) > self.max_position_embeddings - 1:
                tmp = tmp[:self.max_position_embeddings - 1]  # BERTé¢„è®­ç»ƒæ¨¡å‹åªå–å‰512ä¸ªå­—ç¬¦
            tmp += [self.SEP_IDX]
            tensor_ = torch.tensor(tmp, dtype=torch.long)
            l = torch.tensor(int(l), dtype=torch.long)
            max_len = max(max_len, tensor_.size(0))
            data.append((tensor_, l))
        return data, max_len
```

- è¿™ä¸ªæ˜¯pytohnè£…é¥°å™¨

process_cacheæ˜¯

```python
# è¿™ä¸ªæ˜¯pythonè£…é¥°å™¨
# åœ¨ data_processä¸Šé¢å®šä¹‰äº†@process_cache(unique_key=["max_sen_len"])
def process_cache(unique_key=None):
    """
    æ•°æ®é¢„å¤„ç†ç»“æœç¼“å­˜ä¿®é¥°å™¨
    :param : unique_key
    :return:
    """
    if unique_key is None:
        raise ValueError(
            "unique_key ä¸èƒ½ä¸ºç©º, è¯·æŒ‡å®šç›¸å…³æ•°æ®é›†æ„é€ ç±»çš„æˆå‘˜å˜é‡ï¼Œå¦‚['top_k', 'cut_words', 'max_sen_len']")

    def decorating_function(func):
        def wrapper(*args, **kwargs):
            logging.info(f" ## ç´¢å¼•é¢„å¤„ç†ç¼“å­˜æ–‡ä»¶çš„å‚æ•°ä¸ºï¼š{unique_key}")
            obj = args[0]  # è·å–ç±»å¯¹è±¡ï¼Œå› ä¸ºdata_process(self, file_path=None)ä¸­çš„ç¬¬1ä¸ªå‚æ•°ä¸ºself
            file_path = kwargs['file_path']
            file_dir = f"{os.sep}".join(file_path.split(os.sep)[:-1])
            file_name = "".join(file_path.split(os.sep)[-1].split('.')[:-1])
            paras = f"cache_{file_name}_"
            for k in unique_key:
                paras += f"{k}{obj.__dict__[k]}_"  # éå†å¯¹è±¡ä¸­çš„æ‰€æœ‰å‚æ•°
            cache_path = os.path.join(file_dir, paras[:-1] + '.pt')
            start_time = time.time()
            if not os.path.exists(cache_path):
                logging.info(f"ç¼“å­˜æ–‡ä»¶ {cache_path} ä¸å­˜åœ¨ï¼Œé‡æ–°å¤„ç†å¹¶ç¼“å­˜ï¼")
                data = func(*args, **kwargs)
                with open(cache_path, 'wb') as f:
                    torch.save(data, f)
            else:
                logging.info(f"ç¼“å­˜æ–‡ä»¶ {cache_path} å­˜åœ¨ï¼Œç›´æ¥è½½å…¥ç¼“å­˜æ–‡ä»¶ï¼")
                with open(cache_path, 'rb') as f:
                    data = torch.load(f)
            end_time = time.time()
            logging.info(f"æ•°æ®é¢„å¤„ç†ä¸€å…±è€—æ—¶{(end_time - start_time):.3f}s")
            return data

        return wrapper

    return decorating_function
```

### â‘£ paddingå¤„ç†ä¸mask

```python
def pad_sequence(sequences, batch_first=False, max_len=None, padding_value=0):
    """
    å¯¹ä¸€ä¸ªListä¸­çš„å…ƒç´ è¿›è¡Œpadding
    Pad a list of variable length Tensors with ``padding_value``
    a = torch.ones(25)
    b = torch.ones(22)
    c = torch.ones(15)
    pad_sequence([a, b, c],max_len=None).size()
    torch.Size([25, 3])
        sequences:
        batch_first: æ˜¯å¦æŠŠbatch_sizeæ”¾åˆ°ç¬¬ä¸€ä¸ªç»´åº¦
        padding_value:
        max_len :
                å½“max_len = 50æ—¶ï¼Œè¡¨ç¤ºä»¥æŸä¸ªå›ºå®šé•¿åº¦å¯¹æ ·æœ¬è¿›è¡Œpaddingï¼Œå¤šä½™çš„æˆªæ‰ï¼›
                å½“max_len=Noneæ˜¯ï¼Œè¡¨ç¤ºä»¥å½“å‰batchä¸­æœ€é•¿æ ·æœ¬çš„é•¿åº¦å¯¹å…¶å®ƒè¿›è¡Œpaddingï¼›
    Returns:
    """
    # å¦‚æœmax_len=Noneçš„æ—¶å€™ï¼Œé‚£ä¹ˆå°±ä»¤max_lenç­‰äºæ–‡æœ¬ä¸­æœ€é•¿é•¿åº¦
    if max_len is None:
        max_len = max([s.size(0) for s in sequences])
    out_tensors = []
    # éå†æ¯ä¸ªTokenåºåˆ—ï¼Œæ ¹æ®max_lenè¿›è¡Œpadding
    for tensor in sequences:
        # å¦‚æœå½“å‰åºåˆ—é•¿åº¦æ˜¯å°äºmax_len
        if tensor.size(0) < max_len:
            tensor = torch.cat([tensor, torch.tensor([padding_value] * (max_len - tensor.size(0)))], dim=0)
        else:
            tensor = tensor[:max_len]
        out_tensors.append(tensor)
    out_tensors = torch.stack(out_tensors, dim=1)
    # å°†batch_sizeç»´åº¦æ”¾åœ¨å‰é¢
    if batch_first:
        return out_tensors.transpose(0, 1)
    return out_tensors
```

>  åœ¨ä¸Šè¿°ä»£ç ä¸­ï¼Œç¬¬ 1 è¡Œ sequencesä¸ºå¾… padding çš„åºåˆ—æ‰€æ„æˆçš„åˆ—è¡¨ï¼Œå…¶ä¸­çš„æ¯ä¸€ä¸ªå…ƒç´ ä¸ºä¸€ä¸ªæ ·æœ¬çš„ Token åºåˆ—ï¼›batch_first è¡¨ç¤ºæ˜¯å¦å°† batch_size è¿™ä¸ªç»´åº¦æ”¾åœ¨ç¬¬ 1 ä¸ªï¼›max_len è¡¨ç¤ºæŒ‡å®šæœ€å¤§åºåˆ—é•¿åº¦ï¼Œå½“ max_len = 50 æ—¶ï¼Œè¡¨ç¤ºä»¥æŸä¸ªå›ºå®šé•¿åº¦å¯¹æ ·æœ¬è¿›è¡Œ padding å¤šä½™çš„æˆªæ‰ï¼Œå½“ max_len=None æ—¶è¡¨ç¤ºä»¥å½“å‰batchä¸­æœ€é•¿æ ·æœ¬çš„é•¿åº¦å¯¹å…¶å®ƒè¿›è¡Œpaddingã€‚ç¬¬2-3è¡Œç”¨æ¥è·å–paddingçš„é•¿åº¦ï¼›ç¬¬ 5-11 è¡Œåˆ™æ˜¯éå†æ¯ä¸€ä¸ª Token åºåˆ—ï¼Œæ ¹æ® max_len æ¥è¿›è¡Œ paddingã€‚ç¬¬ 12-13è¡Œæ˜¯å°† batch_size è¿™ä¸ªç»´åº¦æ”¾åˆ°æœ€å‰é¢ã€‚



```python
    def generate_batch(self, data_batch):
        batch_sentence, batch_label = [], []
        for (sen, label) in data_batch:  # å¼€å§‹å¯¹ä¸€ä¸ªbatchä¸­çš„æ¯ä¸€ä¸ªæ ·æœ¬è¿›è¡Œå¤„ç†ã€‚
            batch_sentence.append(sen)
            batch_label.append(label)
        batch_sentence = pad_sequence(batch_sentence,  # [batch_size,max_len]
                                      padding_value=self.PAD_IDX,
                                      batch_first=False,
                                      max_len=self.max_sen_len)
        batch_label = torch.tensor(batch_label, dtype=torch.long)
        return batch_sentence, batch_label
```

>ä½œç”¨å°±æ˜¯å¯¹æ¯ä¸ª batch çš„ Token åºåˆ—è¿›è¡Œ padding å¤„ç†ã€‚æœ€åï¼Œå¯¹äºæ¯ä¸€åºåˆ—çš„ attention_mask å‘é‡ï¼Œæˆ‘ä»¬åªéœ€è¦åˆ¤æ–­å…¶æ˜¯å¦ç­‰äºpadding_value ä¾¿å¯ä»¥å¾—åˆ°è¿™ä¸€ç»“æœï¼Œå¯è§ç¬¬ 5 æ­¥ä¸­çš„ä½¿ç”¨ç¤ºä¾‹

### â‘¤æ„é€ DataLoaderå’Œä½¿ç”¨æ¡ˆä¾‹

```python
    def load_train_val_test_data(self, train_file_path=None,
                                 val_file_path=None,
                                 test_file_path=None,
                                 only_test=False):
        # æå–æ–‡æœ¬å‡ºæ¥
        test_data, _ = self.data_process(file_path=test_file_path)
        # DataLoaderæ•°æ®åŠ è½½
        # generate_bathå°±æ˜¯å¯¹
        test_iter = DataLoader(test_data, batch_size=self.batch_size,
                               shuffle=False, collate_fn=self.generate_batch)
        if only_test:
            return test_iter
        train_data, max_sen_len = self.data_process(file_path=train_file_path)  # å¾—åˆ°å¤„ç†å¥½çš„æ‰€æœ‰æ ·æœ¬
        if self.max_sen_len == 'same':
            self.max_sen_len = max_sen_len
        val_data, _ = self.data_process(file_path=val_file_path)
        train_iter = DataLoader(train_data, batch_size=self.batch_size,  # æ„é€ DataLoader
                                shuffle=self.is_sample_shuffle, collate_fn=self.generate_batch)
        val_iter = DataLoader(val_data, batch_size=self.batch_size,
                              shuffle=False, collate_fn=self.generate_batch)
        return train_iter, test_iter, val_iter
```

è¿”å›çš„æ˜¯DataLoaderæ„å»ºçš„æ•°æ®è¿­ä»£å™¨

## åŠ è½½é¢„è®­ç»ƒæ¨¡å‹

>åœ¨ä»‹ç»æ¨¡å‹å¾®è°ƒä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæ¥çœ‹çœ‹å½“æˆ‘ä»¬æ‹¿åˆ°ä¸€ä¸ªå¼€æºçš„æ¨¡å‹å‚æ•°åæ€ä¹ˆè¯»å–ä»¥åŠåˆ†æã€‚ä¸‹é¢æŒæŸœå°±ä»¥ huggingface å¼€æºçš„ PyTorch è®­ç»ƒçš„ bert-baseï¿¾chinese æ¨¡å‹å‚æ•°[10]ä¸ºä¾‹è¿›è¡Œä»‹ç»ã€‚

### â‘ æŸ¥çœ‹æ¨¡å‹å‚æ•°

>PyTorchæ¥è¯»å–å’ŒåŠ è½½æ¨¡å‹å‚æ•°

```python
import sys
sys.path.append('../')
import torch
import os
from Tasks.TaskForSingleSentenceClassification import ModelConfig
from model.BasicBert.BertConfig import BertConfig
from model.BasicBert.Bert import BertModel

if __name__ == '__main__':
    model_config = ModelConfig()
    # /media/wislab/Dataset_SSD2T/lzh/BertWithPretrained/bert_base_chinese/pytorch_model.bin
    bin_path = os.path.join(model_config.pretrained_model_dir,'pytorch_model.bin')

    loaded_paras = torch.load(bin_path)
    print(type(loaded_paras))
    print(len(list(loaded_paras)))
    print(list(loaded_paras.keys()))
    for name in loaded_paras.keys():
        print(f"### å‚æ•°:{name},å½¢çŠ¶{loaded_paras[name].size()}")
```

- è¿™ä¸ªæ˜¯æŸ¥çœ‹é¢„è®­ç»ƒæ¨¡å‹çš„å‚æ•°

```
[2024-09-25 20:06:21] - INFO: æˆåŠŸå¯¼å…¥BERTé…ç½®æ–‡ä»¶ /media/wislab/Dataset_SSD2T/lzh/BertWithPretrained/bert_base_chinese/config.json
[2024-09-25 20:06:21] - INFO:  ### å°†å½“å‰é…ç½®æ‰“å°åˆ°æ—¥å¿—æ–‡ä»¶ä¸­ 
[2024-09-25 20:06:21] - INFO: ###  project_dir = /media/wislab/Dataset_SSD2T/lzh/BertWithPretrained
[2024-09-25 20:06:21] - INFO: ###  dataset_dir = /media/wislab/Dataset_SSD2T/lzh/BertWithPretrained/data/SingleSentenceClassification
[2024-09-25 20:06:21] - INFO: ###  pretrained_model_dir = /media/wislab/Dataset_SSD2T/lzh/BertWithPretrained/bert_base_chinese
[2024-09-25 20:06:21] - INFO: ###  vocab_path = /media/wislab/Dataset_SSD2T/lzh/BertWithPretrained/bert_base_chinese/vocab.txt
[2024-09-25 20:06:21] - INFO: ###  device = cpu
[2024-09-25 20:06:21] - INFO: ###  train_file_path = /media/wislab/Dataset_SSD2T/lzh/BertWithPretrained/data/SingleSentenceClassification/toutiao_train.txt
[2024-09-25 20:06:21] - INFO: ###  val_file_path = /media/wislab/Dataset_SSD2T/lzh/BertWithPretrained/data/SingleSentenceClassification/toutiao_val.txt
[2024-09-25 20:06:21] - INFO: ###  test_file_path = /media/wislab/Dataset_SSD2T/lzh/BertWithPretrained/data/SingleSentenceClassification/toutiao_test.txt
[2024-09-25 20:06:21] - INFO: ###  model_save_dir = /media/wislab/Dataset_SSD2T/lzh/BertWithPretrained/cache
[2024-09-25 20:06:21] - INFO: ###  logs_save_dir = /media/wislab/Dataset_SSD2T/lzh/BertWithPretrained/logs
[2024-09-25 20:06:21] - INFO: ###  split_sep = _!_
[2024-09-25 20:06:21] - INFO: ###  is_sample_shuffle = True
[2024-09-25 20:06:21] - INFO: ###  batch_size = 64
[2024-09-25 20:06:21] - INFO: ###  max_sen_len = None
[2024-09-25 20:06:21] - INFO: ###  num_labels = 15
[2024-09-25 20:06:21] - INFO: ###  epochs = 10
[2024-09-25 20:06:21] - INFO: ###  model_val_per_epoch = 2
[2024-09-25 20:06:21] - INFO: ###  vocab_size = 21128
[2024-09-25 20:06:21] - INFO: ###  hidden_size = 768
[2024-09-25 20:06:21] - INFO: ###  num_hidden_layers = 12
[2024-09-25 20:06:21] - INFO: ###  num_attention_heads = 12
[2024-09-25 20:06:21] - INFO: ###  hidden_act = gelu
[2024-09-25 20:06:21] - INFO: ###  intermediate_size = 3072
[2024-09-25 20:06:21] - INFO: ###  pad_token_id = 0
[2024-09-25 20:06:21] - INFO: ###  hidden_dropout_prob = 0.1
[2024-09-25 20:06:21] - INFO: ###  attention_probs_dropout_prob = 0.1
[2024-09-25 20:06:21] - INFO: ###  max_position_embeddings = 512
[2024-09-25 20:06:21] - INFO: ###  type_vocab_size = 2
[2024-09-25 20:06:21] - INFO: ###  initializer_range = 0.02
[2024-09-25 20:06:21] - INFO: ###  directionality = bidi
[2024-09-25 20:06:21] - INFO: ###  pooler_fc_size = 768
[2024-09-25 20:06:21] - INFO: ###  pooler_num_attention_heads = 12
[2024-09-25 20:06:21] - INFO: ###  pooler_num_fc_layers = 3
[2024-09-25 20:06:21] - INFO: ###  pooler_size_per_head = 128
[2024-09-25 20:06:21] - INFO: ###  pooler_type = first_token_transform
207
### å‚æ•°:bert.embeddings.word_embeddings.weight,å½¢çŠ¶torch.Size([21128, 768])
### å‚æ•°:bert.embeddings.position_embeddings.weight,å½¢çŠ¶torch.Size([512, 768])
### å‚æ•°:bert.embeddings.token_type_embeddings.weight,å½¢çŠ¶torch.Size([2, 768])
### å‚æ•°:bert.embeddings.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.embeddings.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.0.attention.self.query.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.0.attention.self.query.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.0.attention.self.key.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.0.attention.self.key.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.0.attention.self.value.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.0.attention.self.value.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.0.attention.output.dense.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.0.attention.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.0.attention.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.0.attention.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.0.intermediate.dense.weight,å½¢çŠ¶torch.Size([3072, 768])
### å‚æ•°:bert.encoder.layer.0.intermediate.dense.bias,å½¢çŠ¶torch.Size([3072])
### å‚æ•°:bert.encoder.layer.0.output.dense.weight,å½¢çŠ¶torch.Size([768, 3072])
### å‚æ•°:bert.encoder.layer.0.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.0.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.0.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.1.attention.self.query.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.1.attention.self.query.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.1.attention.self.key.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.1.attention.self.key.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.1.attention.self.value.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.1.attention.self.value.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.1.attention.output.dense.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.1.attention.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.1.attention.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.1.attention.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.1.intermediate.dense.weight,å½¢çŠ¶torch.Size([3072, 768])
### å‚æ•°:bert.encoder.layer.1.intermediate.dense.bias,å½¢çŠ¶torch.Size([3072])
### å‚æ•°:bert.encoder.layer.1.output.dense.weight,å½¢çŠ¶torch.Size([768, 3072])
### å‚æ•°:bert.encoder.layer.1.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.1.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.1.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.2.attention.self.query.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.2.attention.self.query.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.2.attention.self.key.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.2.attention.self.key.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.2.attention.self.value.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.2.attention.self.value.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.2.attention.output.dense.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.2.attention.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.2.attention.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.2.attention.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.2.intermediate.dense.weight,å½¢çŠ¶torch.Size([3072, 768])
### å‚æ•°:bert.encoder.layer.2.intermediate.dense.bias,å½¢çŠ¶torch.Size([3072])
### å‚æ•°:bert.encoder.layer.2.output.dense.weight,å½¢çŠ¶torch.Size([768, 3072])
### å‚æ•°:bert.encoder.layer.2.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.2.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.2.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.3.attention.self.query.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.3.attention.self.query.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.3.attention.self.key.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.3.attention.self.key.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.3.attention.self.value.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.3.attention.self.value.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.3.attention.output.dense.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.3.attention.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.3.attention.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.3.attention.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.3.intermediate.dense.weight,å½¢çŠ¶torch.Size([3072, 768])
### å‚æ•°:bert.encoder.layer.3.intermediate.dense.bias,å½¢çŠ¶torch.Size([3072])
### å‚æ•°:bert.encoder.layer.3.output.dense.weight,å½¢çŠ¶torch.Size([768, 3072])
### å‚æ•°:bert.encoder.layer.3.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.3.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.3.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.4.attention.self.query.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.4.attention.self.query.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.4.attention.self.key.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.4.attention.self.key.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.4.attention.self.value.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.4.attention.self.value.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.4.attention.output.dense.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.4.attention.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.4.attention.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.4.attention.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.4.intermediate.dense.weight,å½¢çŠ¶torch.Size([3072, 768])
### å‚æ•°:bert.encoder.layer.4.intermediate.dense.bias,å½¢çŠ¶torch.Size([3072])
### å‚æ•°:bert.encoder.layer.4.output.dense.weight,å½¢çŠ¶torch.Size([768, 3072])
### å‚æ•°:bert.encoder.layer.4.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.4.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.4.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.5.attention.self.query.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.5.attention.self.query.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.5.attention.self.key.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.5.attention.self.key.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.5.attention.self.value.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.5.attention.self.value.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.5.attention.output.dense.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.5.attention.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.5.attention.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.5.attention.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.5.intermediate.dense.weight,å½¢çŠ¶torch.Size([3072, 768])
### å‚æ•°:bert.encoder.layer.5.intermediate.dense.bias,å½¢çŠ¶torch.Size([3072])
### å‚æ•°:bert.encoder.layer.5.output.dense.weight,å½¢çŠ¶torch.Size([768, 3072])
### å‚æ•°:bert.encoder.layer.5.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.5.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.5.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.6.attention.self.query.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.6.attention.self.query.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.6.attention.self.key.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.6.attention.self.key.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.6.attention.self.value.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.6.attention.self.value.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.6.attention.output.dense.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.6.attention.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.6.attention.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.6.attention.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.6.intermediate.dense.weight,å½¢çŠ¶torch.Size([3072, 768])
### å‚æ•°:bert.encoder.layer.6.intermediate.dense.bias,å½¢çŠ¶torch.Size([3072])
### å‚æ•°:bert.encoder.layer.6.output.dense.weight,å½¢çŠ¶torch.Size([768, 3072])
### å‚æ•°:bert.encoder.layer.6.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.6.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.6.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.7.attention.self.query.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.7.attention.self.query.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.7.attention.self.key.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.7.attention.self.key.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.7.attention.self.value.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.7.attention.self.value.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.7.attention.output.dense.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.7.attention.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.7.attention.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.7.attention.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.7.intermediate.dense.weight,å½¢çŠ¶torch.Size([3072, 768])
### å‚æ•°:bert.encoder.layer.7.intermediate.dense.bias,å½¢çŠ¶torch.Size([3072])
### å‚æ•°:bert.encoder.layer.7.output.dense.weight,å½¢çŠ¶torch.Size([768, 3072])
### å‚æ•°:bert.encoder.layer.7.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.7.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.7.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.8.attention.self.query.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.8.attention.self.query.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.8.attention.self.key.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.8.attention.self.key.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.8.attention.self.value.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.8.attention.self.value.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.8.attention.output.dense.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.8.attention.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.8.attention.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.8.attention.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.8.intermediate.dense.weight,å½¢çŠ¶torch.Size([3072, 768])
### å‚æ•°:bert.encoder.layer.8.intermediate.dense.bias,å½¢çŠ¶torch.Size([3072])
### å‚æ•°:bert.encoder.layer.8.output.dense.weight,å½¢çŠ¶torch.Size([768, 3072])
### å‚æ•°:bert.encoder.layer.8.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.8.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.8.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.9.attention.self.query.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.9.attention.self.query.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.9.attention.self.key.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.9.attention.self.key.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.9.attention.self.value.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.9.attention.self.value.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.9.attention.output.dense.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.9.attention.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.9.attention.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.9.attention.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.9.intermediate.dense.weight,å½¢çŠ¶torch.Size([3072, 768])
### å‚æ•°:bert.encoder.layer.9.intermediate.dense.bias,å½¢çŠ¶torch.Size([3072])
### å‚æ•°:bert.encoder.layer.9.output.dense.weight,å½¢çŠ¶torch.Size([768, 3072])
### å‚æ•°:bert.encoder.layer.9.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.9.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.9.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.10.attention.self.query.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.10.attention.self.query.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.10.attention.self.key.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.10.attention.self.key.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.10.attention.self.value.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.10.attention.self.value.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.10.attention.output.dense.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.10.attention.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.10.attention.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.10.attention.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.10.intermediate.dense.weight,å½¢çŠ¶torch.Size([3072, 768])
### å‚æ•°:bert.encoder.layer.10.intermediate.dense.bias,å½¢çŠ¶torch.Size([3072])
### å‚æ•°:bert.encoder.layer.10.output.dense.weight,å½¢çŠ¶torch.Size([768, 3072])
### å‚æ•°:bert.encoder.layer.10.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.10.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.10.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.11.attention.self.query.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.11.attention.self.query.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.11.attention.self.key.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.11.attention.self.key.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.11.attention.self.value.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.11.attention.self.value.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.11.attention.output.dense.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.encoder.layer.11.attention.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.11.attention.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.11.attention.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.11.intermediate.dense.weight,å½¢çŠ¶torch.Size([3072, 768])
### å‚æ•°:bert.encoder.layer.11.intermediate.dense.bias,å½¢çŠ¶torch.Size([3072])
### å‚æ•°:bert.encoder.layer.11.output.dense.weight,å½¢çŠ¶torch.Size([768, 3072])
### å‚æ•°:bert.encoder.layer.11.output.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.11.output.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.encoder.layer.11.output.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:bert.pooler.dense.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:bert.pooler.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:cls.predictions.bias,å½¢çŠ¶torch.Size([21128])
### å‚æ•°:cls.predictions.transform.dense.weight,å½¢çŠ¶torch.Size([768, 768])
### å‚æ•°:cls.predictions.transform.dense.bias,å½¢çŠ¶torch.Size([768])
### å‚æ•°:cls.predictions.transform.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
### å‚æ•°:cls.predictions.transform.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
### å‚æ•°:cls.predictions.decoder.weight,å½¢çŠ¶torch.Size([21128, 768])
### å‚æ•°:cls.seq_relationship.weight,å½¢çŠ¶torch.Size([2, 768])
### å‚æ•°:cls.seq_relationship.bias,å½¢çŠ¶torch.Size([2])
```

>ä½†æ˜¯å¦‚æœè¦å°†æˆ‘ä»¬çš„ç½‘ç»œç»“æœè¿ç§»åˆ°å®˜æ–¹çš„bertæ¨¡å‹ä¸­ï¼Œä½†æ˜¯å‚æ•°å¯¹åº”ä¸ä¸Šåº”è¯¥æ€ä¹ˆåŠ??

### â‘¡ è½½å…¥æ•°æ®å¹¶åˆå§‹åŒ–

>ä½†æ˜¯å¯¹äºå¦‚ä½•è½½å…¥å·²æœ‰å‚æ•°æ¥åˆå§‹åŒ–ç½‘ç»œä¸­çš„å‚æ•°è¿˜å¹¶æœªä»‹ç»ã€‚åœ¨å°†æœ¬åœ°å‚æ•°è¿ç§»åˆ°ä¸€ä¸ªæ–°çš„æ¨¡å‹ä¹‹å‰ï¼Œé™¤äº†åƒä¸Šé¢é‚£æ ·åˆ†ææœ¬åœ°å‚æ•°ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜éœ€è¦å°†ç½‘ç»œçš„å‚æ•°ä¿¡æ¯ä¹Ÿæ‰“å°å‡ºæ¥çœ‹ä¸€ä¸‹ï¼Œä»¥ä¾¿å°†ä¸¤è€…ä¸€ä¸€å¯¹åº”ä¸Š

#### `æŸ¥çœ‹é¢„è®­ç»ƒæ¨¡å‹å’Œè‡ªå·±æ¨¡å‹å‚æ•°çš„åŒºåˆ«`

```python
import sys
sys.path.append('../')
import torch
import os
from Tasks.TaskForSingleSentenceClassification import ModelConfig
from model.BasicBert.BertConfig import BertConfig
from model.BasicBert.Bert import BertModel

if __name__ == '__main__':
    model_config = ModelConfig()
    # /media/wislab/Dataset_SSD2T/lzh/BertWithPretrained/bert_base_chinese/pytorch_model.bin
    bin_path = os.path.join(model_config.pretrained_model_dir,'pytorch_model.bin')

    loaded_paras = torch.load(bin_path)
    # print(type(loaded_paras))
    # print(len(list(loaded_paras)))
    # print(list(loaded_paras.keys()))
    print(len(list(loaded_paras)))
    for name in loaded_paras.keys():
        print(f"### å‚æ•°:{name},å½¢çŠ¶{loaded_paras[name].size()}")
    
    josn_file = os.path.join(model_config.pretrained_model_dir,'config.json')
    # åˆ©ç”¨BertConfig
    config = BertConfig.from_json_file(josn_file)
    bert_model = BertModel(config=config)
    print(len(bert_model.state_dict()))
    for param_tensor in bert_model.state_dict():
        print(param_tensor,"\t",bert_model.state_dict()[param_tensor].size())
    
```

```
200
bert_embeddings.position_ids     torch.Size([1, 512])
bert_embeddings.word_embeddings.embedding.weight         torch.Size([21128, 768])
bert_embeddings.position_embeddings.embedding.weight     torch.Size([512, 768])
bert_embeddings.token_type_embeddings.embedding.weight   torch.Size([2, 768])
bert_embeddings.LayerNorm.weight         torch.Size([768])
bert_embeddings.LayerNorm.bias   torch.Size([768])
bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.q_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.q_proj.bias          torch.Size([768])
bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.k_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.k_proj.bias          torch.Size([768])
bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.v_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.v_proj.bias          torch.Size([768])
bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.out_proj.weight      torch.Size([768, 768])
bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.out_proj.bias        torch.Size([768])
bert_encoder.bert_layers.0.bert_attention.output.LayerNorm.weight        torch.Size([768])
bert_encoder.bert_layers.0.bert_attention.output.LayerNorm.bias          torch.Size([768])
bert_encoder.bert_layers.0.bert_intermediate.dense.weight        torch.Size([3072, 768])
bert_encoder.bert_layers.0.bert_intermediate.dense.bias          torch.Size([3072])
bert_encoder.bert_layers.0.bert_output.dense.weight      torch.Size([768, 3072])
bert_encoder.bert_layers.0.bert_output.dense.bias        torch.Size([768])
bert_encoder.bert_layers.0.bert_output.LayerNorm.weight          torch.Size([768])
bert_encoder.bert_layers.0.bert_output.LayerNorm.bias    torch.Size([768])
bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.q_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.q_proj.bias          torch.Size([768])
bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.k_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.k_proj.bias          torch.Size([768])
bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.v_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.v_proj.bias          torch.Size([768])
bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.out_proj.weight      torch.Size([768, 768])
bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.out_proj.bias        torch.Size([768])
bert_encoder.bert_layers.1.bert_attention.output.LayerNorm.weight        torch.Size([768])
bert_encoder.bert_layers.1.bert_attention.output.LayerNorm.bias          torch.Size([768])
bert_encoder.bert_layers.1.bert_intermediate.dense.weight        torch.Size([3072, 768])
bert_encoder.bert_layers.1.bert_intermediate.dense.bias          torch.Size([3072])
bert_encoder.bert_layers.1.bert_output.dense.weight      torch.Size([768, 3072])
bert_encoder.bert_layers.1.bert_output.dense.bias        torch.Size([768])
bert_encoder.bert_layers.1.bert_output.LayerNorm.weight          torch.Size([768])
bert_encoder.bert_layers.1.bert_output.LayerNorm.bias    torch.Size([768])
bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.q_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.q_proj.bias          torch.Size([768])
bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.k_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.k_proj.bias          torch.Size([768])
bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.v_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.v_proj.bias          torch.Size([768])
bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.out_proj.weight      torch.Size([768, 768])
bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.out_proj.bias        torch.Size([768])
bert_encoder.bert_layers.2.bert_attention.output.LayerNorm.weight        torch.Size([768])
bert_encoder.bert_layers.2.bert_attention.output.LayerNorm.bias          torch.Size([768])
bert_encoder.bert_layers.2.bert_intermediate.dense.weight        torch.Size([3072, 768])
bert_encoder.bert_layers.2.bert_intermediate.dense.bias          torch.Size([3072])
bert_encoder.bert_layers.2.bert_output.dense.weight      torch.Size([768, 3072])
bert_encoder.bert_layers.2.bert_output.dense.bias        torch.Size([768])
bert_encoder.bert_layers.2.bert_output.LayerNorm.weight          torch.Size([768])
bert_encoder.bert_layers.2.bert_output.LayerNorm.bias    torch.Size([768])
bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.q_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.q_proj.bias          torch.Size([768])
bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.k_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.k_proj.bias          torch.Size([768])
bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.v_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.v_proj.bias          torch.Size([768])
bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.out_proj.weight      torch.Size([768, 768])
bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.out_proj.bias        torch.Size([768])
bert_encoder.bert_layers.3.bert_attention.output.LayerNorm.weight        torch.Size([768])
bert_encoder.bert_layers.3.bert_attention.output.LayerNorm.bias          torch.Size([768])
bert_encoder.bert_layers.3.bert_intermediate.dense.weight        torch.Size([3072, 768])
bert_encoder.bert_layers.3.bert_intermediate.dense.bias          torch.Size([3072])
bert_encoder.bert_layers.3.bert_output.dense.weight      torch.Size([768, 3072])
bert_encoder.bert_layers.3.bert_output.dense.bias        torch.Size([768])
bert_encoder.bert_layers.3.bert_output.LayerNorm.weight          torch.Size([768])
bert_encoder.bert_layers.3.bert_output.LayerNorm.bias    torch.Size([768])
bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.q_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.q_proj.bias          torch.Size([768])
bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.k_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.k_proj.bias          torch.Size([768])
bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.v_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.v_proj.bias          torch.Size([768])
bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.out_proj.weight      torch.Size([768, 768])
bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.out_proj.bias        torch.Size([768])
bert_encoder.bert_layers.4.bert_attention.output.LayerNorm.weight        torch.Size([768])
bert_encoder.bert_layers.4.bert_attention.output.LayerNorm.bias          torch.Size([768])
bert_encoder.bert_layers.4.bert_intermediate.dense.weight        torch.Size([3072, 768])
bert_encoder.bert_layers.4.bert_intermediate.dense.bias          torch.Size([3072])
bert_encoder.bert_layers.4.bert_output.dense.weight      torch.Size([768, 3072])
bert_encoder.bert_layers.4.bert_output.dense.bias        torch.Size([768])
bert_encoder.bert_layers.4.bert_output.LayerNorm.weight          torch.Size([768])
bert_encoder.bert_layers.4.bert_output.LayerNorm.bias    torch.Size([768])
bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.q_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.q_proj.bias          torch.Size([768])
bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.k_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.k_proj.bias          torch.Size([768])
bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.v_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.v_proj.bias          torch.Size([768])
bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.out_proj.weight      torch.Size([768, 768])
bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.out_proj.bias        torch.Size([768])
bert_encoder.bert_layers.5.bert_attention.output.LayerNorm.weight        torch.Size([768])
bert_encoder.bert_layers.5.bert_attention.output.LayerNorm.bias          torch.Size([768])
bert_encoder.bert_layers.5.bert_intermediate.dense.weight        torch.Size([3072, 768])
bert_encoder.bert_layers.5.bert_intermediate.dense.bias          torch.Size([3072])
bert_encoder.bert_layers.5.bert_output.dense.weight      torch.Size([768, 3072])
bert_encoder.bert_layers.5.bert_output.dense.bias        torch.Size([768])
bert_encoder.bert_layers.5.bert_output.LayerNorm.weight          torch.Size([768])
bert_encoder.bert_layers.5.bert_output.LayerNorm.bias    torch.Size([768])
bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.q_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.q_proj.bias          torch.Size([768])
bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.k_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.k_proj.bias          torch.Size([768])
bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.v_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.v_proj.bias          torch.Size([768])
bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.out_proj.weight      torch.Size([768, 768])
bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.out_proj.bias        torch.Size([768])
bert_encoder.bert_layers.6.bert_attention.output.LayerNorm.weight        torch.Size([768])
bert_encoder.bert_layers.6.bert_attention.output.LayerNorm.bias          torch.Size([768])
bert_encoder.bert_layers.6.bert_intermediate.dense.weight        torch.Size([3072, 768])
bert_encoder.bert_layers.6.bert_intermediate.dense.bias          torch.Size([3072])
bert_encoder.bert_layers.6.bert_output.dense.weight      torch.Size([768, 3072])
bert_encoder.bert_layers.6.bert_output.dense.bias        torch.Size([768])
bert_encoder.bert_layers.6.bert_output.LayerNorm.weight          torch.Size([768])
bert_encoder.bert_layers.6.bert_output.LayerNorm.bias    torch.Size([768])
bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.q_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.q_proj.bias          torch.Size([768])
bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.k_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.k_proj.bias          torch.Size([768])
bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.v_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.v_proj.bias          torch.Size([768])
bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.out_proj.weight      torch.Size([768, 768])
bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.out_proj.bias        torch.Size([768])
bert_encoder.bert_layers.7.bert_attention.output.LayerNorm.weight        torch.Size([768])
bert_encoder.bert_layers.7.bert_attention.output.LayerNorm.bias          torch.Size([768])
bert_encoder.bert_layers.7.bert_intermediate.dense.weight        torch.Size([3072, 768])
bert_encoder.bert_layers.7.bert_intermediate.dense.bias          torch.Size([3072])
bert_encoder.bert_layers.7.bert_output.dense.weight      torch.Size([768, 3072])
bert_encoder.bert_layers.7.bert_output.dense.bias        torch.Size([768])
bert_encoder.bert_layers.7.bert_output.LayerNorm.weight          torch.Size([768])
bert_encoder.bert_layers.7.bert_output.LayerNorm.bias    torch.Size([768])
bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.q_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.q_proj.bias          torch.Size([768])
bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.k_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.k_proj.bias          torch.Size([768])
bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.v_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.v_proj.bias          torch.Size([768])
bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.out_proj.weight      torch.Size([768, 768])
bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.out_proj.bias        torch.Size([768])
bert_encoder.bert_layers.8.bert_attention.output.LayerNorm.weight        torch.Size([768])
bert_encoder.bert_layers.8.bert_attention.output.LayerNorm.bias          torch.Size([768])
bert_encoder.bert_layers.8.bert_intermediate.dense.weight        torch.Size([3072, 768])
bert_encoder.bert_layers.8.bert_intermediate.dense.bias          torch.Size([3072])
bert_encoder.bert_layers.8.bert_output.dense.weight      torch.Size([768, 3072])
bert_encoder.bert_layers.8.bert_output.dense.bias        torch.Size([768])
bert_encoder.bert_layers.8.bert_output.LayerNorm.weight          torch.Size([768])
bert_encoder.bert_layers.8.bert_output.LayerNorm.bias    torch.Size([768])
bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.q_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.q_proj.bias          torch.Size([768])
bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.k_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.k_proj.bias          torch.Size([768])
bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.v_proj.weight        torch.Size([768, 768])
bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.v_proj.bias          torch.Size([768])
bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.out_proj.weight      torch.Size([768, 768])
bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.out_proj.bias        torch.Size([768])
bert_encoder.bert_layers.9.bert_attention.output.LayerNorm.weight        torch.Size([768])
bert_encoder.bert_layers.9.bert_attention.output.LayerNorm.bias          torch.Size([768])
bert_encoder.bert_layers.9.bert_intermediate.dense.weight        torch.Size([3072, 768])
bert_encoder.bert_layers.9.bert_intermediate.dense.bias          torch.Size([3072])
bert_encoder.bert_layers.9.bert_output.dense.weight      torch.Size([768, 3072])
bert_encoder.bert_layers.9.bert_output.dense.bias        torch.Size([768])
bert_encoder.bert_layers.9.bert_output.LayerNorm.weight          torch.Size([768])
bert_encoder.bert_layers.9.bert_output.LayerNorm.bias    torch.Size([768])
bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.q_proj.weight       torch.Size([768, 768])
bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.q_proj.bias         torch.Size([768])
bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.k_proj.weight       torch.Size([768, 768])
bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.k_proj.bias         torch.Size([768])
bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.v_proj.weight       torch.Size([768, 768])
bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.v_proj.bias         torch.Size([768])
bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.out_proj.weight     torch.Size([768, 768])
bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.out_proj.bias       torch.Size([768])
bert_encoder.bert_layers.10.bert_attention.output.LayerNorm.weight       torch.Size([768])
bert_encoder.bert_layers.10.bert_attention.output.LayerNorm.bias         torch.Size([768])
bert_encoder.bert_layers.10.bert_intermediate.dense.weight       torch.Size([3072, 768])
bert_encoder.bert_layers.10.bert_intermediate.dense.bias         torch.Size([3072])
bert_encoder.bert_layers.10.bert_output.dense.weight     torch.Size([768, 3072])
bert_encoder.bert_layers.10.bert_output.dense.bias       torch.Size([768])
bert_encoder.bert_layers.10.bert_output.LayerNorm.weight         torch.Size([768])
bert_encoder.bert_layers.10.bert_output.LayerNorm.bias   torch.Size([768])
bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.q_proj.weight       torch.Size([768, 768])
bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.q_proj.bias         torch.Size([768])
bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.k_proj.weight       torch.Size([768, 768])
bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.k_proj.bias         torch.Size([768])
bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.v_proj.weight       torch.Size([768, 768])
bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.v_proj.bias         torch.Size([768])
bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.out_proj.weight     torch.Size([768, 768])
bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.out_proj.bias       torch.Size([768])
bert_encoder.bert_layers.11.bert_attention.output.LayerNorm.weight       torch.Size([768])
bert_encoder.bert_layers.11.bert_attention.output.LayerNorm.bias         torch.Size([768])
bert_encoder.bert_layers.11.bert_intermediate.dense.weight       torch.Size([3072, 768])
bert_encoder.bert_layers.11.bert_intermediate.dense.bias         torch.Size([3072])
bert_encoder.bert_layers.11.bert_output.dense.weight     torch.Size([768, 3072])
bert_encoder.bert_layers.11.bert_output.dense.bias       torch.Size([768])
bert_encoder.bert_layers.11.bert_output.LayerNorm.weight         torch.Size([768])
bert_encoder.bert_layers.11.bert_output.LayerNorm.bias   torch.Size([768])
bert_pooler.dense.weight         torch.Size([768, 768])
bert_pooler.dense.bias   torch.Size([768])
```

#### å°†é¢„è®­ç»ƒæ¨¡å‹å‚æ•°èµ‹å€¼ç»™è‡ªå·±çš„æ¨¡å‹å‚æ•°

>è§‚å¯Ÿä¸Šé¢çš„ç»“æœï¼Œå‘ç°å‚æ•°åªæœ‰è¿™éƒ¨åˆ†çš„æ˜¯å’Œbert-base-chineseä¸­æœ‰åŒºåˆ«
>
>### å‚æ•°:cls.predictions.bias,å½¢çŠ¶torch.Size([21128])
>### å‚æ•°:cls.predictions.transform.dense.weight,å½¢çŠ¶torch.Size([768, 768])
>### å‚æ•°:cls.predictions.transform.dense.bias,å½¢çŠ¶torch.Size([768])
>### å‚æ•°:cls.predictions.transform.LayerNorm.gamma,å½¢çŠ¶torch.Size([768])
>### å‚æ•°:cls.predictions.transform.LayerNorm.beta,å½¢çŠ¶torch.Size([768])
>### å‚æ•°:cls.predictions.decoder.weight,å½¢çŠ¶torch.Size([21128, 768])
>### å‚æ•°:cls.seq_relationship.weight,å½¢çŠ¶torch.Size([2, 768])
>### å‚æ•°:cls.seq_relationship.bias,å½¢çŠ¶torch.Size([2])
>
>é‚£ä¹ˆå°±éœ€è¦å°†bert-base-chineseèµ‹ç»™è‡ªå·±çš„Bertæ¨¡å‹

```python
    def from_pretrained(cls, config, pretrained_model_dir=None):
        model = cls(config)  # åˆå§‹åŒ–æ¨¡å‹ï¼Œclsä¸ºæœªå®ä¾‹åŒ–çš„å¯¹è±¡ï¼Œå³ä¸€ä¸ªæœªå®ä¾‹åŒ–çš„BertModelå¯¹è±¡
        # è¿™ä¸ªæ˜¯é¢„è®­ç»ƒæ¨¡å‹ï¼Œ
        pretrained_model_path = os.path.join(pretrained_model_dir, "pytorch_model.bin")
        if not os.path.exists(pretrained_model_path):
            raise ValueError(f"<è·¯å¾„ï¼š{pretrained_model_path} ä¸­çš„æ¨¡å‹ä¸å­˜åœ¨ï¼Œè¯·ä»”ç»†æ£€æŸ¥ï¼>\n"
                             f"ä¸­æ–‡æ¨¡å‹ä¸‹è½½åœ°å€ï¼šhttps://huggingface.co/bert-base-chinese/tree/main\n"
                             f"è‹±æ–‡æ¨¡å‹ä¸‹è½½åœ°å€ï¼šhttps://huggingface.co/bert-base-uncased/tree/main\n")
        # ä¿å­˜æ¨¡å‹çš„æ–¹æ³•,è¿™ä¸ªéœ€è¦é‡ç‚¹å…³æ³¨ï¼Œæ˜¯åæœŸè°ƒè¯•æ¨¡å‹çš„é‡ç‚¹
        loaded_paras = torch.load(pretrained_model_path)
        # æ‹·è´ä¸€ä»½BertModelä¸­çš„ç½‘ç»œå‚æ•°,æ— æ³•ä¿®æ”¹é‡Œé¢çš„å€¼
        state_dict = deepcopy(model.state_dict())
        # å› ä¸ºbert-base-chineseä¸­çš„å‚æ•°æ˜¯207
        # ä¸”å‘ç°BertModelä¸­çš„å‚æ•°æ˜¯200
        # é‚£ä¹ˆéœ€è¦å°†bert-base-chinseä¸­çš„å‚æ•°èµ‹å€¼åˆ°state_dict
        # loaded_paras_namesæ˜¯bert-base-chineseä¸­çš„å‚æ•°
        loaded_paras_names = list(loaded_paras.keys())[:-8]
        # model_paras_namesæ˜¯BertModelä¸­å‚æ•°
        model_paras_names = list(state_dict.keys())[1:]
        if 'use_torch_multi_head' in config.__dict__ and config.use_torch_multi_head:
            torch_paras = format_paras_for_torch(loaded_paras_names, loaded_paras)
            for i in range(len(model_paras_names)):
                logging.debug(f"## æˆåŠŸèµ‹å€¼å‚æ•°:{model_paras_names[i]},å½¢çŠ¶ä¸º: {torch_paras[i].size()}")
                if "position_embeddings" in model_paras_names[i]:
                    # è¿™éƒ¨åˆ†ä»£ç ç”¨æ¥æ¶ˆé™¤é¢„è®­ç»ƒæ¨¡å‹åªèƒ½è¾“å…¥å°äº512ä¸ªå­—ç¬¦çš„é™åˆ¶
                    if config.max_position_embeddings > 512:
                        new_embedding = replace_512_position(state_dict[model_paras_names[i]],
                                                             loaded_paras[loaded_paras_names[i]])
                        state_dict[model_paras_names[i]] = new_embedding
                        continue
                # é‚£ä¹ˆéœ€è¦å°†bert-base-chinseä¸­çš„å‚æ•°èµ‹å€¼åˆ°state_dict
                state_dict[model_paras_names[i]] = torch_paras[i]
            logging.info(f"## æ³¨æ„ï¼Œæ­£åœ¨ä½¿ç”¨torchæ¡†æ¶ä¸­çš„MultiHeadAttentionå®ç°")
        else:
            for i in range(len(loaded_paras_names)):
                logging.debug(f"## æˆåŠŸå°†å‚æ•°:{loaded_paras_names[i]}èµ‹å€¼ç»™{model_paras_names[i]},"
                              f"å‚æ•°å½¢çŠ¶ä¸º:{state_dict[model_paras_names[i]].size()}")
                if "position_embeddings" in model_paras_names[i]:
                    # è¿™éƒ¨åˆ†ä»£ç ç”¨æ¥æ¶ˆé™¤é¢„è®­ç»ƒæ¨¡å‹åªèƒ½è¾“å…¥å°äº512ä¸ªå­—ç¬¦çš„é™åˆ¶
                    if config.max_position_embeddings > 512:
                        new_embedding = replace_512_position(state_dict[model_paras_names[i]],
                                                             loaded_paras[loaded_paras_names[i]])
                        state_dict[model_paras_names[i]] = new_embedding
                        continue
                # è¿™ä¸ªä»£ç å¾ˆé‡è¦ï¼Œæ˜¯å°†bert-base-chineseä¸­çš„å‚æ•°èµ‹ç»™è‡ªå·±çš„BERTæ¨¡å‹ä¸­
                state_dict[model_paras_names[i]] = loaded_paras[loaded_paras_names[i]]
            logging.info(f"## æ³¨æ„ï¼Œæ­£åœ¨ä½¿ç”¨æœ¬åœ°MyTransformerä¸­çš„MyMultiHeadAttentionå®ç°ï¼Œ"
                         f"å¦‚éœ€ä½¿ç”¨torchæ¡†æ¶ä¸­çš„MultiHeadAttentionæ¨¡å—å¯é€šè¿‡config.__dict__['use_torch_multi_head'] = Trueå®ç°")
        model.load_state_dict(state_dict)
        return model
```

>è¿™ä¸ªä»£ç ä»£è¡¨å°†state_dict[model_paras_names[i]]=loaded_paras[loaded_paras_names[i]]ï¼Œä¹Ÿå°±æ˜¯å°†

- å‡å¦‚å¼•å…¥é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œè®­ç»ƒ

```python
import sys
sys.path.append('../')
import torch
import os
from Tasks.TaskForSingleSentenceClassification import ModelConfig
from model.BasicBert.BertConfig import BertConfig
from model.BasicBert.Bert import BertModel

if __name__ == '__main__':
    model_config = ModelConfig()
    # # /media/wislab/Dataset_SSD2T/lzh/BertWithPretrained/bert_base_chinese/pytorch_model.bin
    # bin_path = os.path.join(model_config.pretrained_model_dir,'pytorch_model.bin')

    # loaded_paras = torch.load(bin_path)
    # # print(type(loaded_paras))
    # # print(len(list(loaded_paras)))
    # # print(list(loaded_paras.keys()))
    # print(len(list(loaded_paras)))
    # for name in loaded_paras.keys():
    #     print(f"### å‚æ•°:{name},å½¢çŠ¶{loaded_paras[name].size()}")
    # # ==========æµ‹è¯•æœ¬æ¨¡å‹Configä¸­ä¸bert-base-chineseä¸­çš„åŒºåˆ«==========
    # # çœ‹bert_model ä¸BertModelçš„åŒºåˆ«
    josn_file = os.path.join(model_config.pretrained_model_dir,'config.json')
    config = BertConfig.from_json_file(josn_file)
    # bert_model = BertModel(config=config)
    # print(len(bert_model.state_dict()))
    # for param_tensor in bert_model.state_dict():
    #     print(param_tensor,"\t",bert_model.state_dict()[param_tensor].size())
    # è¿™ä¸ªæ˜¯åˆå€¼çš„èµ‹äºˆ
    # from_pretrainedæ˜¯ç±»ä¼¼åå°„æœºåˆ¶ï¼Œå°±æ˜¯ä¸éœ€è¦é€šè¿‡å®ä¾‹åŒ–ç±»ç›´æ¥å¯ä»¥åˆå§‹åŒ–
    bert = BertModel.from_pretrained(config=config,pretrained_model_dir=model_config.pretrained_model_dir)
    # å‡å¦‚æˆ‘å†»ç»“æŸäº›å±‚çš„å‚æ•°ä¸å‚ä¸æ¨¡å‹è®­ç»ƒ
    # for para in bert.parameters():
    
```

## æ–‡æœ¬åˆ†ç±»

### å‰å‘ä¼ æ’­

>ä»‹ç»å¦‚ä½•åˆ†æå’Œè½½å…¥æœ¬åœ°BERTé¢„è®­ç»ƒæ¨¡å‹å, æ¥ä¸‹æ¥æˆ‘ä»¬é¦–å…ˆè¦åšçš„å°±æ˜¯å®ç°æ–‡æœ¬åˆ†ç±»çš„å‰å‘ä¼ æ’­è¿‡ç¨‹
>
>å®šä¹‰ä¸€ä¸ªç±»æ¥å®Œæˆæ•´ä¸ªå‰å‘ä¼ æ’­è¿‡ç¨‹

```python
from ..BasicBert.Bert import BertModel
import torch.nn as nn

"""
å®šä¹‰ä¸€ä¸ªç±»è¿›è¡Œå®ç°æ–‡æœ¬çš„å‰å‘ä¼ æ’­
bert_pretrained_model_dir = /home/wislab/lzh/BertWithPretrained/bert_base_chinese
"""
class BertForSentenceClassification(nn.Module):
    def __init__(self, config, bert_pretrained_model_dir=None):
        super(BertForSentenceClassification, self).__init__()
        self.num_labels = config.num_labels
        # é€šè¿‡BertModelè¿›è¡ŒåŠ è½½ï¼Œè¿”å›ä¸€ä¸ªmodel
        # self.bertæ˜¯ä¸€ä¸ªmodel
        # å¦‚æœbert_pretrained_model_diræ˜¯å­˜åœ¨,é‚£ä¹ˆéœ€è¦å¯¼å…¥é¢„è®­ç»ƒå¥½çš„pytorch_model.binæ–‡ä»¶
        # å¦‚æœä¸å­˜åœ¨,åˆ™é‡æ–°åˆ©ç”¨è‡ªå·±çš„configè®­ç»ƒæ–‡ä»¶
        # è¿™å¥è¯çš„æ„æ€å°±æ˜¯æ˜¯å¦å­˜åœ¨é¢„è®­ç»ƒæ¨¡å‹,å¦‚æœå­˜åœ¨,é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥å°†å…¶å¼•å…¥
        # ç”¨BertModel.from_pretrainedè¿›è¡Œå¼•å…¥
        if bert_pretrained_model_dir is not None:
            self.bert = BertModel.from_pretrained(config, bert_pretrained_model_dir)
        else:
            self.bert = BertModel(config)
        # "hidden_dropout_prob": 0.1,
        # é¢„è®­ç»ƒå¥½çš„æ¨¡å‹çš„hidden_dropout_prob
        self.dropout = nn.Dropout(config.hidden_dropout_prob)
        self.classifier = nn.Linear(config.hidden_size, self.num_labels)
```

>`å¦‚æœå­˜åœ¨bert_pretrained_model_dir`ä¹Ÿå°±æ˜¯`bert_pretrained_modelä¸­å­˜åœ¨binæ¨¡å‹ï¼Œé‚£ä¹ˆå°±éœ€è¦å¯¼å…¥è¯¥æ¨¡å‹è¿›è¡Œä¿®æ”¹æœ¬æ¨¡å‹çš„å‚æ•°`



```python
    def forward(self, input_ids,
                attention_mask=None,
                token_type_ids=None,
                position_ids=None,
                labels=None):
        """

        :param input_ids:  [src_len, batch_size]
        :param attention_mask: [batch_size, src_len]
        :param token_type_ids: å¥å­åˆ†ç±»æ—¶ä¸ºNone
        :param position_ids: [1,src_len]
        :param labels: [batch_size,]
        :return:
        """
        # return pooled_output, all_encoder_outputs
        # pooled_output æ˜¯pooled_output
        # _æ˜¯all_encoder_outputs
        pooled_output, _ = self.bert(input_ids=input_ids,
                                     attention_mask=attention_mask,
                                     token_type_ids=token_type_ids,
                                     position_ids=position_ids)  # [batch_size,hidden_size]
        pooled_output = self.dropout(pooled_output)
        # å› ä¸ºæ˜¯åˆ†ç±»é—®é¢˜,æˆ‘ä»¬æ˜¯ç›´æ¥åœ¨BERTä¹‹åæ·»åŠ ä¸€ä¸ªåˆ†ç±»å™¨
        # classifieræ˜¯ä¸€ä¸ªåˆ†ç±»å™¨,åŸºäºTransformerå›¾6.1ç»“æ„å›¾å¯çŸ¥
        # æ–‡æœ¬åˆ†ç±»æ˜¯åŠ ä¸€ä¸ªåˆ†ç±»å™¨è¿›å»çš„
        logits = self.classifier(pooled_output)  # [batch_size, num_label]
        if labels is not None:
            # è¿™å¥è¯çš„æ„æ€å°±æ˜¯å¦‚æœæ²¡å®šä¹‰label
            loss_fct = nn.CrossEntropyLoss()
            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))
            return loss, logits
        else:
            return logits

```

>```python
>        pooled_output, _ = self.bert(input_ids=input_ids,
>                                     attention_mask=attention_mask,
>                                     token_type_ids=token_type_ids,
>                                     position_ids=position_ids)  # [batch_size,hidden_size]
>```
>
>è¿™éƒ¨åˆ†æ˜¯åŸå§‹çš„BERTç½‘ç»œçš„è¾“å‡ºï¼Œå…¶ä¸­pooled_outputä¸ºBERTç¬¬ä¸€ä¸ªä½ç½®çš„å‘é‡ç»è¿‡ä¸€ä¸ªå…¨è¿æ¥å±‚åçš„ç»“æœï¼›
>
>ç¬¬2ä¸ªå‚æ•°æ˜¯BERTä¸­æ‰€æœ‰ä½ç½®çš„å‘é‡ï¼Œ
>
>

>```python
>        pooled_output = self.dropout(pooled_output)
>        # å› ä¸ºæ˜¯åˆ†ç±»é—®é¢˜,æˆ‘ä»¬æ˜¯ç›´æ¥åœ¨BERTä¹‹åæ·»åŠ ä¸€ä¸ªåˆ†ç±»å™¨
>        # classifieræ˜¯ä¸€ä¸ªåˆ†ç±»å™¨,åŸºäºTransformerå›¾6.1ç»“æ„å›¾å¯çŸ¥
>        # æ–‡æœ¬åˆ†ç±»æ˜¯åŠ ä¸€ä¸ªåˆ†ç±»å™¨è¿›å»çš„
>        logits = self.classifier(pooled_output)  # [batch_size, num_label]
>```
>
>pooled_outæ˜¯ç”¨æ¥è¿›è¡Œæ–‡æœ¬åˆ†ç±»çš„åˆ†ç±»å±‚

>```python
>        if labels is not None:
>            # è¿™å¥è¯çš„æ„æ€å°±æ˜¯å¦‚æœæ²¡å®šä¹‰label
>            loss_fct = nn.CrossEntropyLoss()
>            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))
>            return loss, logits
>        else:
>            return logits
>```
>
>å‡å¦‚labelsæ˜¯ç©ºçš„ï¼Œé‚£ä¹ˆè¿”å›loss,æˆ–è€…è¿”å›logits

### æ¨¡å‹è®­ç»ƒ

>TaskForSingleSentenceClassification.pyæ¨¡å—æ¥å®Œæˆæ¨¡å‹çš„å¾®è°ƒè®­ç»ƒä»»åŠ¡

```python
class ModelConfig:
    """
    ModelConfigæ˜¯è¿›è¡Œä¸‹æ¸¸è®­ç»ƒåˆå§‹åŒ–å‚æ•°çš„ç±»
    project_diræ˜¯æœ¬é¡¹ç›®å­˜åœ¨çš„æ ¹ç›®å½•.ä¾‹å¦‚/home/wislab/lzh/BertWithPretrained
    dataset_diræ˜¯/home/wislab/lzh/BertWithPretrained/data/SingleSentenceClassification
    pretrained_model_dir = /home/wislab/lzh/BertWithPretrained/bert_base_chinese
    vocab_path = /home/wislab/lzh/BertWithPretrained/bert_base_chinese/vocab.txt
    train_file_path = /home/wislab/lzh/BertWithPretrained/data/SingleSentenceClassification/toutiao_train.txt
    val_file_path = /home/wislab/lzh/BertWithPretrained/data/SingleSentenceClassification/toutiao_val.txt
    test_file_path = /home/wislab/lzh/BertWithPretrained/data/SingleSentenceClassification/toutiao_test.txt
    model_save_dir = /home/wislab/lzh/BertWithPretrained/cache
    logs_save_dir = /home/wislab/lzh/BertWithPretrained/logs
    bert_config_path = /home/wislab/lzh/BertWithPretrained/bert_base_chinese/config.json
    """
    def __init__(self):
        self.project_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        self.dataset_dir = os.path.join(self.project_dir, 'data', 'SingleSentenceClassification')
        self.pretrained_model_dir = os.path.join(self.project_dir, "bert_base_chinese")
        self.vocab_path = os.path.join(self.pretrained_model_dir, 'vocab.txt')
        # torch.device('cuda:0' if torch.cuda.is_available())
        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        self.train_file_path = os.path.join(self.dataset_dir, 'toutiao_train.txt')
        self.val_file_path = os.path.join(self.dataset_dir, 'toutiao_val.txt')
        self.test_file_path = os.path.join(self.dataset_dir, 'toutiao_test.txt')
        self.model_save_dir = os.path.join(self.project_dir, 'cache')
        self.logs_save_dir = os.path.join(self.project_dir, 'logs')
        self.split_sep = '_!_'
        self.is_sample_shuffle = True
        self.batch_size = 64
        self.max_sen_len = None
        self.num_labels = 15
        self.epochs = 10
        self.model_val_per_epoch = 2
        # logger_initæ˜¯æ—¥å¿—å‡½æ•°ç”¨æ¥æ‰“å°æ—¥å¿—çš„
        # ä¿å­˜ä¸º/home/wislab/lzh/BertWithPretrained/logs/single.txt
        logger_init(log_file_name='single', log_level=logging.INFO,
                    log_dir=self.logs_save_dir)
        # å¦‚æœos.pathé‡Œé¢ä¸å­˜åœ¨model_save_diræ–‡ä»¶å¤¹
        # é‚£ä¹ˆåˆ›é€ model_save_diræ–‡ä»¶å¤¹
        if not os.path.exists(self.model_save_dir):
            os.makedirs(self.model_save_dir)

        # æŠŠåŸå§‹bertä¸­çš„é…ç½®å‚æ•°ä¹Ÿå¯¼å…¥è¿›æ¥
        bert_config_path = os.path.join(self.pretrained_model_dir, "config.json")
        bert_config = BertConfig.from_json_file(bert_config_path)
        # ä»bert_config.__dict__é‡Œé¢å–å‡ºitems()
        # items()æ˜¯key:valueå½¢å¼ä¹Ÿå°±æ˜¯é”®å€¼å½¢å¼
        # é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥å°†å…¶æ”¾è¿›è‡ªå·±çš„__dict__ä¸­
        for key, value in bert_config.__dict__.items():
            self.__dict__[key] = value
        # å°†å½“å‰é…ç½®æ‰“å°åˆ°æ—¥å¿—æ–‡ä»¶ä¸­
        logging.info(" ### å°†å½“å‰é…ç½®æ‰“å°åˆ°æ—¥å¿—æ–‡ä»¶ä¸­ ")
        for key, value in self.__dict__.items():
            logging.info(f"###  {key} = {value}")

```

>åˆå§‹åŒ–ä»£ç :è¿™ä¸ªç±»ä»£ç æ˜¯ç”¨æ¥åˆå§‹åŒ–å„ç±»å‚æ•°çš„
>
>è®¾ç½®æ‰“å°ä»»åŠ¡ç”¨çš„



```python
"""
trainè¿‡ç¨‹,å¯¼å…¥configå¯¹è±¡
"""
def train(config):
    # å¼•ç”¨model/DownstreamTasksä¸­æ¨¡å—
    # Bertæ˜¯ForSentenceClassificationç”Ÿæˆçš„ä¸€ä¸ªmodel
    # åˆå§‹åŒ–ä¹‹åä¼šæœ‰model
    model = BertForSentenceClassification(config,
                                          config.pretrained_model_dir)
    # æ‰“å°çœ‹çœ‹modelåˆ°åº•æ˜¯ä»€ä¹ˆ
    print(model)
    model_save_path = os.path.join(config.model_save_dir, 'model.pt')
    if os.path.exists(model_save_path):
        loaded_paras = torch.load(model_save_path)
        model.load_state_dict(loaded_paras)
        logging.info("## æˆåŠŸè½½å…¥å·²æœ‰æ¨¡å‹ï¼Œè¿›è¡Œè¿½åŠ è®­ç»ƒ......")
    # å°†è¯¥æ¨¡å‹åŠ å…¥åˆ°è®¾å¤‡é‡Œé¢,å¯ä»¥ä½¿å¾—æ¨¡å‹è½¬ç§»åˆ°æŒ‡å®šçš„è®¾å¤‡é‡Œé¢è¿è¡Œ
    model = model.to(config.device)
    # .Variableçš„åŸºæœ¬æ¦‚å¿µ, .Variableçš„è‡ªåŠ¨æ±‚å¯¼
    # variableç±»å‹
    optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)
    # è¿›è¡Œè®­ç»ƒ
    model.train()
    # Transformeré‡Œé¢çš„BertTokenizerç±»
    # å¾—ä»”ç»†ç ”è¯»ä¸€ä¸‹
    bert_tokenize = BertTokenizer.from_pretrained(config.pretrained_model_dir).tokenize
    # åŠ è½½æ•°æ®é›†åˆ,LoadSingleSentenceClassificationDatasetå·²ç»å†™å¥½å†data_helper.pyé‡Œé¢äº†
    data_loader = LoadSingleSentenceClassificationDataset(vocab_path=config.vocab_path,
                                                          tokenizer=bert_tokenize,
                                                          batch_size=config.batch_size,
                                                          max_sen_len=config.max_sen_len,
                                                          split_sep=config.split_sep,
                                                          max_position_embeddings=config.max_position_embeddings,
                                                          pad_index=config.pad_token_id,
                                                          is_sample_shuffle=config.is_sample_shuffle)
    # data_loaderçš„å·¥ä½œåŸç†,å¾—ä»”ç»†ç ”è¯»ä¸€ä¸‹
    train_iter, test_iter, val_iter = data_loader.load_train_val_test_data(config.train_file_path,
                                                                           config.val_file_path,
                                                                           config.test_file_path)
    max_acc = 0
    for epoch in range(config.epochs):
        losses = 0
        start_time = time.time()
        for idx, (sample, label) in enumerate(train_iter):
            sample = sample.to(config.device)  # [src_len, batch_size]
            label = label.to(config.device)
            padding_mask = (sample == data_loader.PAD_IDX).transpose(0, 1)
            loss, logits = model(
                input_ids=sample,
                attention_mask=padding_mask,
                token_type_ids=None,
                position_ids=None,
                labels=label)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            losses += loss.item()
            acc = (logits.argmax(1) == label).float().mean()
            if idx % 10 == 0:
                logging.info(f"Epoch: {epoch}, Batch[{idx}/{len(train_iter)}], "
                             f"Train loss :{loss.item():.3f}, Train acc: {acc:.3f}")
        end_time = time.time()
        train_loss = losses / len(train_iter)
        logging.info(f"Epoch: {epoch}, Train loss: {train_loss:.3f}, Epoch time = {(end_time - start_time):.3f}s")
        if (epoch + 1) % config.model_val_per_epoch == 0:
            acc = evaluate(val_iter, model, config.device, data_loader.PAD_IDX)
            logging.info(f"Accuracy on val {acc:.3f}")
            if acc > max_acc:
                max_acc = acc
                torch.save(model.state_dict(), model_save_path)

```

>- åˆå§‹åŒ–ä¸€ä¸ªåŸºäºBERTçš„åˆ†ç±»æ¨¡å‹
>
>  ```python
>      # å¼•ç”¨model/DownstreamTasksä¸­æ¨¡å—
>      # Bertæ˜¯ForSentenceClassificationç”Ÿæˆçš„ä¸€ä¸ªmodel
>      # åˆå§‹åŒ–ä¹‹åä¼šæœ‰model
>      model = BertForSentenceClassification(config,
>                                            config.pretrained_model_dir)
>      # æ‰“å°çœ‹çœ‹modelåˆ°åº•æ˜¯ä»€ä¹ˆ
>      print(model)
>      model_save_path = os.path.join(config.model_save_dir, 'model.pt')
>      if os.path.exists(model_save_path):
>          loaded_paras = torch.load(model_save_path)
>          model.load_state_dict(loaded_paras)
>          logging.info("## æˆåŠŸè½½å…¥å·²æœ‰æ¨¡å‹ï¼Œè¿›è¡Œè¿½åŠ è®­ç»ƒ......")
>      # å°†è¯¥æ¨¡å‹åŠ å…¥åˆ°è®¾å¤‡é‡Œé¢,å¯ä»¥ä½¿å¾—æ¨¡å‹è½¬ç§»åˆ°æŒ‡å®šçš„è®¾å¤‡é‡Œé¢è¿è¡Œ
>      model = model.to(config.device)
>      # .Variableçš„åŸºæœ¬æ¦‚å¿µ, .Variableçš„è‡ªåŠ¨æ±‚å¯¼
>      # variableç±»å‹
>      optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)
>      # è¿›è¡Œè®­ç»ƒ
>      model.train()
>  ```
>
>- è½½å…¥ç›¸åº”çš„æ•°æ®é›†
>
>```python
>    data_loader = LoadSingleSentenceClassificationDataset(vocab_path=config.vocab_path,
>                                                          tokenizer=bert_tokenize,
>                                                          batch_size=config.batch_size,
>                                                          max_sen_len=config.max_sen_len,
>                                                          split_sep=config.split_sep,
>                                                          max_position_embeddings=config.max_position_embeddings,
>                                                          pad_index=config.pad_token_id,
>                                                          is_sample_shuffle=config.is_sample_shuffle)
>    # data_loaderçš„å·¥ä½œåŸç†,å¾—ä»”ç»†ç ”è¯»ä¸€ä¸‹
>    train_iter, test_iter, val_iter = data_loader.load_train_val_test_data(config.train_file_path,
>                                                                       config.val_file_path,
>                                                                           config.test_file_path)
>```
>
>- è¿›è¡Œè®­ç»ƒ
>
>```python
>    max_acc = 0
>    for epoch in range(config.epochs):
>        losses = 0
>        start_time = time.time()
>        for idx, (sample, label) in enumerate(train_iter):
>            sample = sample.to(config.device)  # [src_len, batch_size]
>            label = label.to(config.device)
>            padding_mask = (sample == data_loader.PAD_IDX).transpose(0, 1)
>            loss, logits = model(
>                input_ids=sample,
>                attention_mask=padding_mask,
>                token_type_ids=None,
>                position_ids=None,
>                labels=label)
>            optimizer.zero_grad()
>            loss.backward()
>            optimizer.step()
>            losses += loss.item()
>            acc = (logits.argmax(1) == label).float().mean()
>            if idx % 10 == 0:
>                logging.info(f"Epoch: {epoch}, Batch[{idx}/{len(train_iter)}], "
>                             f"Train loss :{loss.item():.3f}, Train acc: {acc:.3f}")
>        end_time = time.time()
>        train_loss = losses / len(train_iter)
>        logging.info(f"Epoch: {epoch}, Train loss: {train_loss:.3f}, Epoch time = {(end_time - start_time):.3f}s")
>        if (epoch + 1) % config.model_val_per_epoch == 0:
>            acc = evaluate(val_iter, model, config.device, data_loader.PAD_IDX)
>            logging.info(f"Accuracy on val {acc:.3f}")
>            if acc > max_acc:
>                max_acc = acc
>                torch.save(model.state_dict(), model_save_path)
>```
>
>

# ä¸‹æ¸¸ä»»åŠ¡äºŒ: æ–‡æœ¬è•´å«ä»»åŠ¡

## ä»»åŠ¡æ„é€ åŸç†

>`åŒæ—¶ç»™æ¨¡å‹è¾“å…¥ä¸¤å¥è¯ï¼Œç„¶åè®©æ¨¡å‹æ¥åˆ¤æ–­ä¸¤å¥è¯ä¹‹é—´çš„å…³ç³»ï¼Œæ‰€ä»¥æœ¬è´¨ä¸Šä¹Ÿå°±å˜æˆäº†ä¸€ä¸ªæ–‡æœ¬åˆ†ç±»ä»»åŠ¡`
>
>æœ€ç»ˆéƒ½æ˜¯å¯¹ä¸€ä¸ªæ–‡æœ¬åºåˆ—è¿›è¡Œåˆ†ç±»ã€‚åªæ˜¯æŒ‰ç…§ BERT æ¨¡å‹çš„æ€æƒ³ï¼Œ`æ–‡æœ¬å¯¹åˆ†ç±»ä»»åŠ¡åœ¨æ•°æ®é›†çš„æ„å»ºè¿‡ç¨‹ä¸­éœ€è¦é€šè¿‡ Segment Embeddingæ¥åŒºåˆ†å‰åä¸¤ä¸ªä¸åŒçš„åºåˆ—ï¼Œå¹¶ä¸”ä¸¤ä¸ªå¥å­ä¹‹é—´éœ€è¦é€šè¿‡ä¸€ä¸ª[SEP]ç¬¦å·æ¥è¿›è¡Œåˆ†
>å‰²ï¼Œå› æ­¤æœ¬èŠ‚å†…å®¹çš„æ ¸å¿ƒå°±åœ¨äºå¦‚ä½•æ„å»ºæ•°æ®é›†`
>
>`æ–‡æœ¬å¯¹çš„åˆ†ç±»ä»»åŠ¡é™¤äº†åœ¨æ¨¡å‹è¾“å…¥ä¸Šå‘ç”Ÿäº†å˜æ¢ï¼Œå…¶å®ƒåœ°æ–¹å‡ä¸å•æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ä¸€æ ·ï¼ŒåŒæ ·ä¹Ÿæ˜¯å–æœ€åä¸€å±‚çš„[CLS]å‘é‡è¿›è¡Œåˆ†ç±»ã€‚æ¥ä¸‹æ¥æŒæŸœé¦–å…ˆå°±æ¥ä»‹ç»å¦‚ä½•æ„é€ æ–‡æœ¬åˆ†ç±»çš„æ•°æ®é›†`

## æ•°æ®é¢„å¤„ç†

### è¾“å…¥æ•°æ®

>ä¸ä»…ä»…éœ€è¦è¿›è¡ŒToken Embeddingæ“ä½œï¼ŒåŒæ—¶è¿˜è¦å¯¹`ä¸¤ä¸ªåºåˆ—è¿›è¡ŒSegment Embedding æ“ä½œ`ã€‚å¯¹äº Position Embedding æ¥è¯´åœ¨ä»»ä½•åœºæ™¯ä¸‹éƒ½ä¸éœ€è¦å¯¹å…¶æŒ‡å®šè¾“å…¥ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨ä»£ç å®ç°æ—¶å·²ç»åšäº†ç›¸åº”é»˜è®¤æ—¶çš„å¤„ç†
>
>- éœ€è¦æ„é€ åŸå§‹æ–‡æœ¬å¯¹åº”çš„Tokenåºåˆ—,ç„¶ååœ¨æœ€å‰é¢åŠ ä¸Šä¸€ä¸ª[CLS]ç¬¦,ä¸¤ä¸ªåºåˆ—ä¹‹é—´ä»¥åŠæ•´ä¸ªåºåˆ—çš„æœ«å°¾åˆ†åˆ«å†åŠ ä¸Šä¸€ä¸ª[SEP]ç¬¦å·
>- æ ¹æ®ä¸¤ä¸ªåºåˆ—å„è‡ªçš„é•¿åº¦å†æ„å»ºä¸€ä¸ªç±»ä¼¼[0,0,0,...,1,1,1,...]çš„token_type_idså‘é‡
>- æœ€åå°†ä¸¤è€…ä½œä¸ºæ¨¡å‹çš„è¾“å…¥å³å¯

### æ•°æ®é›†åˆ†æ

![](https://pic.superbed.cc/item/66f5425e991d0115dfc8b3aa.png)

>â‘ åŸå§‹æ•°æ®æ ·æœ¬è¿›è¡Œåˆ†è¯(tokenize)å¤„ç† -> â‘¡æ ¹æ®tokenizeåç»“æœæ„å»ºå­—å…¸ -> â‘¢å°†tokenizeåçš„æ–‡æœ¬åºåˆ—è½¬æ¢ä¸ºToken idåºåˆ—,åŒæ—¶åœ¨Token idåºåˆ—èµ·å§‹ä½ç½®åŠ ä¸Š[CLS],ä¸¤ä¸ªåºåˆ—ä¹‹é—´ä»¥åŠæ•´ä¸ªåºåˆ—æœ«å°¾åŠ ä¸Š[SEP]ç¬¦å· ï¼Œå¹¶è¿›è¡Œpadding->â‘£ æ ¹æ®ç¬¬ä¸‰æ­¥åˆ†åˆ«ç”Ÿæˆå¯¹åº”çš„token types ids å’Œattention maskå‘é‡

## æ•°æ®é›†æ„å»º

### â‘  å®šä¹‰tokenize

>å’Œtransformersæ¨¡å‹ç±»ä¼¼ï¼Œéœ€è¦å…ˆå¯¹æ–‡æœ¬è¿›è¡Œtokenizeræ“ä½œ

```python
# Tokenizerçš„æ“ä½œ,åº•å±‚æºç ä¸ç”¨ç®¡
import sys
sys.path.append('../')
from Tasks.TaskForPairSentenceClassification import ModelConfig
from transformers import BertTokenizer

if __name__ == '__main__':
    model_config = ModelConfig()
    tokenizer = BertTokenizer.from_pretrained(model_config.pretrained_model_dir).tokenize
    # print(tokenizer("é’å±±ä¸æ”¹ï¼Œç»¿æ°´é•¿æµï¼Œæˆ‘ä»¬æœˆæ¥å®¢æ ˆè§ï¼"))
    # print(tokenizer("10 å¹´å‰çš„ä»Šå¤©ï¼Œçºªå¿µ 5.12 æ±¶å·å¤§åœ°éœ‡ 10 å‘¨å¹´"))
    print(tokenizer("From Home Work to Modern Manufacture. Modern manufacturing has changed over time."))
```

### â‘¡å»ºç«‹è¯è¡¨

> å› ä¸ºè°·æ­Œæ˜¯å¼€æºäº† vocab.txt è¯è¡¨,  ä¸éœ€è¦æ ¹æ®è‡ªå·±çš„è¯­æ–™æ¥å»ºç«‹ä¸€ä¸ªè¯è¡¨
>
> `ä¸èƒ½æ ¹æ®è‡ªå·±çš„è¯­æ–™æ¥æ„å»ºè¯è¡¨`,å› ä¸ºå½“ç”¨è‡ªå·±çš„è¯­æ–™æ„å»ºè¯è¡¨çš„æ—¶å€™ï¼Œä¼šå¯¼è‡´åæœŸæå–çš„token.idæ˜¯é”™è¯¯çš„

> è¯¥æ–‡ä»¶åœ¨"/media/wislab/Dataset_SSD2T/lzh/BertWithPretrained/utils/data_helpers.py"

```python
# æµ‹è¯•è½½å…¥æ•°æ®
import sys

sys.path.append('../')
from Tasks.TaskForPairSentenceClassification import ModelConfig
from utils.data_helpers import LoadPairSentenceClassificationDataset
from transformers import BertTokenizer

vocab_path = ""

class Vocab:
    """
    æ ¹æ®æœ¬åœ°çš„vocabæ–‡ä»¶ï¼Œæ„é€ ä¸€ä¸ªè¯è¡¨
    vocab = Vocab()
    print(vocab.itos)  # å¾—åˆ°ä¸€ä¸ªåˆ—è¡¨ï¼Œè¿”å›è¯è¡¨ä¸­çš„æ¯ä¸€ä¸ªè¯ï¼›
    print(vocab.itos[2])  # é€šè¿‡ç´¢å¼•è¿”å›å¾—åˆ°è¯è¡¨ä¸­å¯¹åº”çš„è¯ï¼›
    print(vocab.stoi)  # å¾—åˆ°ä¸€ä¸ªå­—å…¸ï¼Œè¿”å›è¯è¡¨ä¸­æ¯ä¸ªè¯çš„ç´¢å¼•ï¼›
    print(vocab.stoi['æˆ‘'])  # é€šè¿‡å•è¯è¿”å›å¾—åˆ°è¯è¡¨ä¸­å¯¹åº”çš„ç´¢å¼•
    print(len(vocab))  # è¿”å›è¯è¡¨é•¿åº¦
    """
    UNK = '[UNK]'

    def __init__(self, vocab_path):
        self.stoi = {}
        self.itos = []
        with open(vocab_path, 'r', encoding='utf-8') as f:
            # enumerate() å‡½æ•°ç”¨äºå°†ä¸€ä¸ªå¯éå†çš„æ•°æ®å¯¹è±¡(å¦‚åˆ—è¡¨ã€å…ƒç»„æˆ–å­—ç¬¦ä¸²)ç»„åˆä¸ºä¸€ä¸ªç´¢å¼•åºåˆ—ï¼Œ
            # åŒæ—¶åˆ—å‡ºæ•°æ®å’Œæ•°æ®ä¸‹æ ‡ï¼Œä¸€èˆ¬ç”¨åœ¨ for å¾ªç¯å½“ä¸­ã€‚
            for i, word in enumerate(f):
                # å»é™¤å¤´å°¾\n
                w = word.strip('\n')
                self.stoi[w] = i
                self.itos.append(w)

    def __getitem__(self, token):
        return self.stoi.get(token, self.stoi.get(Vocab.UNK))

    def __len__(self):
        return len(self.itos)


def build_vocab(vocab_path):
    """
    vocab = Vocab()
    print(vocab.itos)  # å¾—åˆ°ä¸€ä¸ªåˆ—è¡¨ï¼Œè¿”å›è¯è¡¨ä¸­çš„æ¯ä¸€ä¸ªè¯ï¼›
    print(vocab.itos[2])  # é€šè¿‡ç´¢å¼•è¿”å›å¾—åˆ°è¯è¡¨ä¸­å¯¹åº”çš„è¯ï¼›
    print(vocab.stoi)  # å¾—åˆ°ä¸€ä¸ªå­—å…¸ï¼Œè¿”å›è¯è¡¨ä¸­æ¯ä¸ªè¯çš„ç´¢å¼•ï¼›
    print(vocab.stoi['æˆ‘'])  # é€šè¿‡å•è¯è¿”å›å¾—åˆ°è¯è¡¨ä¸­å¯¹åº”çš„ç´¢å¼•
    """
    return Vocab(vocab_path)

if __name__ == '__main__':
    model_config = ModelConfig()
    vocab = build_vocab(model_config.vocab_path)
    print(vocab.itos)  # å¾—åˆ°ä¸€ä¸ªåˆ—è¡¨ï¼Œè¿”å›è¯è¡¨ä¸­çš„æ¯ä¸€ä¸ªè¯ï¼›
    print(vocab.itos[2])  # é€šè¿‡ç´¢å¼•è¿”å›å¾—åˆ°è¯è¡¨ä¸­å¯¹åº”çš„è¯ï¼›
    print(vocab.stoi)  # å¾—åˆ°ä¸€ä¸ªå­—å…¸ï¼Œè¿”å›è¯è¡¨ä¸­æ¯ä¸ªè¯çš„ç´¢å¼•ï¼›
    # print(vocab.stoi['æˆ‘'])  # é€šè¿‡å•è¯è¿”å›å¾—åˆ°è¯è¡¨ä¸­å¯¹åº”çš„ç´¢å¼•

```

>è¾“å‡ºç»“æœ

```python
, 'atkins': 21087, 'turrets': 21088, 'inadvertently': 21089, 'disagree': 21090, 'libre': 21091, 'vodka': 21092, 'reassuring': 21093, 'weighs': 21094, '##yal': 21095, 'glide': 21096, 'jumper': 21097, 'ceilings': 21098, 'repertory': 21099, 'outs': 21100, 'stain': 21101, '##bial': 21102, 'envy': 21103, '##ucible': 21104, 'smashing': 21105, 'heightened': 21106, 'policing': 21107, 'hyun': 21108, 'mixes': 21109, 'lai': 21110, 'prima': 21111, '##ples': 21112, 'celeste': 21113, '##bina': 21114, 'lucrative': 21115, 'intervened': 21116, 'kc': 21117, 'manually': 21118, '##rned': 21119, 'stature': 21120, 'staffed': 21121, 'bun': 21122, 'bastards': 21123, 'nairobi': 21124, 'priced': 21125, '##auer': 21126, 'thatcher': 21127, '##kia': 21128, 'tripped': 21129, 'comune': 21130, '##ogan': 21131, '##pled': 21132, 'brasil': 21133, 'incentives': 21134, 'emanuel': 21135, 'hereford': 21136, 'musica': 21137, '##kim': 21138, 'benedictine': 21139, 'biennale': 21140, '##lani': 21141, 'eureka': 21142, 'gardiner': 21143, 'rb': 21144, 'knocks': 21145, 'sha': 21146, '##ael': 21147, '##elled': 21148, '##onate': 21149, 'efficacy': 21150, 'ventura': 21151, 'masonic': 21152, 'sanford': 21153, 'maize': 21154, 'leverage': 21155, '##feit': 21156, 'capacities': 21157, 'santana': 21158, '##aur': 21159, 'novelty': 21160, 'vanilla': 21161, '##cter': 21162, '##tour': 21163, 'benin': 21164, '##oir': 21165, '##rain': 21166,....
```

### â‘¢è½¬æ¢ä¸ºTokenåºåˆ—

```python
class LoadPairSentenceClassificationDataset(LoadSingleSentenceClassificationDataset):
    def __init__(self, **kwargs):
        super(LoadPairSentenceClassificationDataset, self).__init__(**kwargs)
        pass
```

>æŒ‰ç…§å‰ä¸€ç¯‡çš„æ–¹æ³•,è¿™é‡Œç»§æ‰¿äº†LoadSingleSentenceClassificationDatasetçš„æ–¹æ³•
>
>é‡å†™data_process()å’Œgenerate_batch()æ–¹æ³•



```python
     # data_process()ç›¸å½“äºè°ƒç”¨äº†
    # data_process = process_cache(unique_key=["max_sen_len"])(data_process)
    # ç›¸å½“äºé¦–å…ˆæ‰§è¡Œäº†process_cache(unique_key=["max_sen_len"]),è¿”å›çš„æ˜¯decorating_functionå‡½æ•°
    # å†è°ƒç”¨è¿”å›çš„å‡½æ•°,å‚æ•°æ˜¯data_process(self, file_path=None),è¿”å›å€¼æ˜¯wrapperå‡½æ•°
    @process_cache(unique_key=["max_sen_len"])
    def data_process(self, file_path=None):
        """
        å°†æ¯ä¸€å¥è¯ä¸­çš„æ¯ä¸€ä¸ªè¯æ ¹æ®å­—å…¸è½¬æ¢æˆç´¢å¼•çš„å½¢å¼ï¼ŒåŒæ—¶è¿”å›æ‰€æœ‰æ ·æœ¬ä¸­æœ€é•¿æ ·æœ¬çš„é•¿åº¦
        :param filepath: æ•°æ®é›†è·¯å¾„
        :return:
        """
        raw_iter = open(file_path).readlines()
        data = []
        max_len = 0
        # tqdmæ˜¯pythonçš„è¿›åº¦æ¡åº“ï¼Œå¯ä»¥åœ¨pythoné•¿å¾ªç¯ä¸­æ·»åŠ ä¸€ä¸ªè¿›åº¦æç¤ºä¿¡æ¯
        for raw in tqdm(raw_iter, ncols=80):
            # å–å¾—æ–‡æœ¬å’Œæ ‡ç­¾;
            line = raw.rstrip("\n").split(self.split_sep)
            s1, s2, l = line[0], line[1], line[2]
            # åˆ†åˆ«å¯¹ä¸¤ä¸ªåºåˆ—s1å’Œs2è½¬æ¢ä¸ºè¯è¡¨ä¸­å¯¹åº”çš„Token
            token1 = [self.vocab[token] for token in self.tokenizer(s1)]
            token2 = [self.vocab[token] for token in self.tokenizer(s2)]
            # å°†ä¸¤ä¸ªåºåˆ—æ‹¼æ¥èµ·æ¥ï¼Œå¹¶åœ¨åºåˆ—çš„å¼€å§‹åŠ ä¸Š[CLS]ç¬¦å·
            # åœ¨ä¸¤ä¸ªåºåˆ—ä¹‹é—´åŠæœ«å°¾åŠ ä¸Š[SEP]ç¬¦å·
            tmp = [self.CLS_IDX] + token1 + [self.SEP_IDX] + token2
            if len(tmp) > self.max_position_embeddings - 1:
                tmp = tmp[:self.max_position_embeddings - 1]  # BERTé¢„è®­ç»ƒæ¨¡å‹åªå–å‰512ä¸ªå­—ç¬¦
            tmp += [self.SEP_IDX]
            # æ„é€ Segment Embeddingçš„è¾“å…¥å‘é‡
            seg1 = [0] * (len(token1) + 2)  # 2 è¡¨ç¤º[CLS]å’Œä¸­é—´çš„[SEP]è¿™ä¸¤ä¸ªå­—ç¬¦
            seg2 = [1] * (len(tmp) - len(seg1))
            segs = torch.tensor(seg1 + seg2, dtype=torch.long)
            # æ•´åˆå¾—åˆ°å¯¹åº”çš„æ ·æœ¬æ•°æ®
            tensor_ = torch.tensor(tmp, dtype=torch.long)
            l = torch.tensor(int(l), dtype=torch.long)
            max_len = max(max_len, tensor_.size(0))
            data.append((tensor_, segs, l))
        return data, max_len
```



```
[2024-09-26 20:20:54] - INFO:  ## ç´¢å¼•é¢„å¤„ç†ç¼“å­˜æ–‡ä»¶çš„å‚æ•°ä¸ºï¼š['max_sen_len']
[2024-09-26 20:20:54] - INFO: ç¼“å­˜æ–‡ä»¶ /media/wislab/Dataset_SSD2T/lzh/BertWithPretrained/data/PairSentenceClassification/cache_test_max_sen_lenNone.pt ä¸å­˜åœ¨ï¼Œé‡æ–°å¤„ç†å¹¶ç¼“å­˜ï¼
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39271/39271 [00:18<00:00, 2106.22it/s]
[2024-09-26 20:21:15] - INFO: æ•°æ®é¢„å¤„ç†ä¸€å…±è€—æ—¶21.049s
[2024-09-26 20:21:15] - INFO:  ## ç´¢å¼•é¢„å¤„ç†ç¼“å­˜æ–‡ä»¶çš„å‚æ•°ä¸ºï¼š['max_sen_len']
[2024-09-26 20:21:15] - INFO: ç¼“å­˜æ–‡ä»¶ /media/wislab/Dataset_SSD2T/lzh/BertWithPretrained/data/PairSentenceClassification/cache_train_max_sen_lenNone.pt ä¸å­˜åœ¨ï¼Œé‡æ–°å¤„ç†å¹¶ç¼“å­˜ï¼
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274891/274891 [02:11<00:00, 2097.04it/s]
[2024-09-26 20:23:43] - INFO: æ•°æ®é¢„å¤„ç†ä¸€å…±è€—æ—¶147.958s
[2024-09-26 20:23:43] - INFO:  ## ç´¢å¼•é¢„å¤„ç†ç¼“å­˜æ–‡ä»¶çš„å‚æ•°ä¸ºï¼š['max_sen_len']
[2024-09-26 20:23:43] - INFO: ç¼“å­˜æ–‡ä»¶ /media/wislab/Dataset_SSD2T/lzh/BertWithPretrained/data/PairSentenceClassification/cache_val_max_sen_lenNone.pt ä¸å­˜åœ¨ï¼Œé‡æ–°å¤„ç†å¹¶ç¼“å­˜ï¼
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78540/78540 [00:37<00:00, 2121.24it/s]
[2024-09-26 20:24:25] - INFO: æ•°æ®é¢„å¤„ç†ä¸€å…±è€—æ—¶42.038s
torch.Size([70, 16])
tensor([[ 101, 1998, 2061,  ...,    0,    0,    0],
        [ 101, 1998, 2116,  ...,    0,    0,    0],
        [ 101, 1998, 1996,  ...,    0,    0,    0],
        ...,
        [ 101, 1999, 2621,  ...,    0,    0,    0],
        [ 101, 2035, 1997,  ...,    0,    0,    0],
        [ 101, 2273, 2293,  ...,    0,    0,    0]])
torch.Size([16, 70])
torch.Size([16])
torch.Size([70, 16])
tensor([1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0, 2, 1, 0, 2])
tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]])
```

>`æ³¨æ„:`è¿™ä¸ªæ˜¯åº”è¯¥è¦äº‹å…ˆåˆ¤æ–­cache_train_max_sen_lenNone.ptæ˜¯å¦å­˜åœ¨
>
>`è¿™éƒ¨åˆ†å†…å®¹å¯ä»¥çœ‹Pytonè¯­æ³•åŸºç¡€çš„mdç¬”è®°ï¼Œå…¶ä¸­åœ¨pythonè£…é¥°å™¨é‚£ä¸€ç« `
>
>çœ‹è¾“å‡ºç»“æœ101å°±æ˜¯[CLS]åœ¨è¯è¡¨ä¸­çš„ç´¢å¼•ä½ç½®,102 åˆ™æ˜¯[SEP]åœ¨è¯è¡¨ä¸­çš„ç´¢å¼•ï¼›å…¶å®ƒé 0 å€¼å°±æ˜¯ tokenize åçš„æ–‡æœ¬åºåˆ—è½¬æ¢æˆçš„ Tokenåºåˆ—
>
>

### â‘£ paddingå¤„ç†ä¸mask

